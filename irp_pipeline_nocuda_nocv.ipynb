{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16440\\658619301.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  time_shifted[features] = time_shifted[features].astype(float)\n",
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16440\\658619301.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  time_shifted[features] = scaler.fit_transform(time_shifted[features])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Mortgage_rate</th>\n",
       "      <th>Unemp_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>DFF</th>\n",
       "      <th>GDP</th>\n",
       "      <th>GVZ</th>\n",
       "      <th>OVX</th>\n",
       "      <th>VVIX</th>\n",
       "      <th>RSI (14D)</th>\n",
       "      <th>20 Day CCI</th>\n",
       "      <th>Williams %R</th>\n",
       "      <th>EMA (5D)</th>\n",
       "      <th>MA50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-09-18</th>\n",
       "      <td>-1.176076</td>\n",
       "      <td>-1.177533</td>\n",
       "      <td>-1.176933</td>\n",
       "      <td>-1.176824</td>\n",
       "      <td>-1.176824</td>\n",
       "      <td>0.109361</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.482353</td>\n",
       "      <td>1.456424</td>\n",
       "      <td>1.657579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585650</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>1.117324</td>\n",
       "      <td>0.270120</td>\n",
       "      <td>-1.493092</td>\n",
       "      <td>1.482107</td>\n",
       "      <td>0.984329</td>\n",
       "      <td>1.006778</td>\n",
       "      <td>-1.180615</td>\n",
       "      <td>-1.208577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-21</th>\n",
       "      <td>-1.179205</td>\n",
       "      <td>-1.176708</td>\n",
       "      <td>-1.177451</td>\n",
       "      <td>-1.175624</td>\n",
       "      <td>-1.175624</td>\n",
       "      <td>-0.299288</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.482353</td>\n",
       "      <td>1.456424</td>\n",
       "      <td>1.657579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591876</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>1.243262</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>-1.455507</td>\n",
       "      <td>1.539945</td>\n",
       "      <td>0.832566</td>\n",
       "      <td>1.066556</td>\n",
       "      <td>-1.178910</td>\n",
       "      <td>-1.206776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-22</th>\n",
       "      <td>-1.172563</td>\n",
       "      <td>-1.174806</td>\n",
       "      <td>-1.173036</td>\n",
       "      <td>-1.173711</td>\n",
       "      <td>-1.173711</td>\n",
       "      <td>-0.244979</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.482353</td>\n",
       "      <td>1.456424</td>\n",
       "      <td>1.657579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591876</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>1.518226</td>\n",
       "      <td>0.194489</td>\n",
       "      <td>-1.624331</td>\n",
       "      <td>1.632955</td>\n",
       "      <td>0.820504</td>\n",
       "      <td>1.069644</td>\n",
       "      <td>-1.177134</td>\n",
       "      <td>-1.205111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-23</th>\n",
       "      <td>-1.172005</td>\n",
       "      <td>-1.170893</td>\n",
       "      <td>-1.174682</td>\n",
       "      <td>-1.177157</td>\n",
       "      <td>-1.177157</td>\n",
       "      <td>-0.116712</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.482353</td>\n",
       "      <td>1.456424</td>\n",
       "      <td>1.657579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591876</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>1.402783</td>\n",
       "      <td>0.244323</td>\n",
       "      <td>-1.629260</td>\n",
       "      <td>1.163946</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>0.589041</td>\n",
       "      <td>-1.177101</td>\n",
       "      <td>-1.203546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-24</th>\n",
       "      <td>-1.174869</td>\n",
       "      <td>-1.176689</td>\n",
       "      <td>-1.182443</td>\n",
       "      <td>-1.182671</td>\n",
       "      <td>-1.182671</td>\n",
       "      <td>-0.167261</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.482353</td>\n",
       "      <td>1.456424</td>\n",
       "      <td>1.657579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598102</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>-1.469062</td>\n",
       "      <td>0.497239</td>\n",
       "      <td>0.276534</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>-1.178920</td>\n",
       "      <td>-1.202392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23</th>\n",
       "      <td>2.494212</td>\n",
       "      <td>2.498853</td>\n",
       "      <td>2.523222</td>\n",
       "      <td>2.497305</td>\n",
       "      <td>2.497305</td>\n",
       "      <td>1.383573</td>\n",
       "      <td>0</td>\n",
       "      <td>1.755746</td>\n",
       "      <td>1.341485</td>\n",
       "      <td>-1.004953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.633200</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.389731</td>\n",
       "      <td>-0.605202</td>\n",
       "      <td>-0.376635</td>\n",
       "      <td>-0.304872</td>\n",
       "      <td>-0.509211</td>\n",
       "      <td>-1.056645</td>\n",
       "      <td>2.504898</td>\n",
       "      <td>2.447403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-24</th>\n",
       "      <td>2.436585</td>\n",
       "      <td>2.411178</td>\n",
       "      <td>2.370387</td>\n",
       "      <td>2.345624</td>\n",
       "      <td>2.345624</td>\n",
       "      <td>2.579649</td>\n",
       "      <td>0</td>\n",
       "      <td>1.755746</td>\n",
       "      <td>1.341485</td>\n",
       "      <td>-1.004953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.633200</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.276387</td>\n",
       "      <td>-0.598753</td>\n",
       "      <td>0.708398</td>\n",
       "      <td>-1.463285</td>\n",
       "      <td>-1.774386</td>\n",
       "      <td>-1.987103</td>\n",
       "      <td>2.453630</td>\n",
       "      <td>2.452126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>2.348285</td>\n",
       "      <td>2.364595</td>\n",
       "      <td>2.305113</td>\n",
       "      <td>2.308410</td>\n",
       "      <td>2.308410</td>\n",
       "      <td>2.166303</td>\n",
       "      <td>1</td>\n",
       "      <td>1.755746</td>\n",
       "      <td>1.341485</td>\n",
       "      <td>-1.004953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.633200</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.368741</td>\n",
       "      <td>-0.619859</td>\n",
       "      <td>0.601189</td>\n",
       "      <td>-1.677050</td>\n",
       "      <td>-2.058419</td>\n",
       "      <td>-1.766556</td>\n",
       "      <td>2.407028</td>\n",
       "      <td>2.455868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-26</th>\n",
       "      <td>2.343493</td>\n",
       "      <td>2.343927</td>\n",
       "      <td>2.353219</td>\n",
       "      <td>2.349207</td>\n",
       "      <td>2.349207</td>\n",
       "      <td>1.612174</td>\n",
       "      <td>1</td>\n",
       "      <td>1.755746</td>\n",
       "      <td>1.341485</td>\n",
       "      <td>-1.004953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.633200</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.440106</td>\n",
       "      <td>-0.427558</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>-1.293841</td>\n",
       "      <td>-1.693177</td>\n",
       "      <td>-1.422492</td>\n",
       "      <td>2.389579</td>\n",
       "      <td>2.459861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29</th>\n",
       "      <td>2.369536</td>\n",
       "      <td>2.362493</td>\n",
       "      <td>2.367191</td>\n",
       "      <td>2.373997</td>\n",
       "      <td>2.373997</td>\n",
       "      <td>-0.318052</td>\n",
       "      <td>0</td>\n",
       "      <td>1.755746</td>\n",
       "      <td>1.341485</td>\n",
       "      <td>-1.004953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.633200</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.440106</td>\n",
       "      <td>-0.427558</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>-1.070572</td>\n",
       "      <td>-1.422687</td>\n",
       "      <td>-1.213430</td>\n",
       "      <td>2.386223</td>\n",
       "      <td>2.463269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3739 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2009-09-18 -1.176076 -1.177533 -1.176933 -1.176824  -1.176824  0.109361   \n",
       "2009-09-21 -1.179205 -1.176708 -1.177451 -1.175624  -1.175624 -0.299288   \n",
       "2009-09-22 -1.172563 -1.174806 -1.173036 -1.173711  -1.173711 -0.244979   \n",
       "2009-09-23 -1.172005 -1.170893 -1.174682 -1.177157  -1.177157 -0.116712   \n",
       "2009-09-24 -1.174869 -1.176689 -1.182443 -1.182671  -1.182671 -0.167261   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "2024-07-23  2.494212  2.498853  2.523222  2.497305   2.497305  1.383573   \n",
       "2024-07-24  2.436585  2.411178  2.370387  2.345624   2.345624  2.579649   \n",
       "2024-07-25  2.348285  2.364595  2.305113  2.308410   2.308410  2.166303   \n",
       "2024-07-26  2.343493  2.343927  2.353219  2.349207   2.349207  1.612174   \n",
       "2024-07-29  2.369536  2.362493  2.367191  2.373997   2.373997 -0.318052   \n",
       "\n",
       "            Target       CPI  Mortgage_rate  Unemp_rate  ...       DFF  \\\n",
       "Date                                                     ...             \n",
       "2009-09-18       1 -1.482353       1.456424    1.657579  ... -0.585650   \n",
       "2009-09-21       1 -1.482353       1.456424    1.657579  ... -0.591876   \n",
       "2009-09-22       0 -1.482353       1.456424    1.657579  ... -0.591876   \n",
       "2009-09-23       0 -1.482353       1.456424    1.657579  ... -0.591876   \n",
       "2009-09-24       0 -1.482353       1.456424    1.657579  ... -0.598102   \n",
       "...            ...       ...            ...         ...  ...       ...   \n",
       "2024-07-23       0  1.755746       1.341485   -1.004953  ...  2.633200   \n",
       "2024-07-24       0  1.755746       1.341485   -1.004953  ...  2.633200   \n",
       "2024-07-25       1  1.755746       1.341485   -1.004953  ...  2.633200   \n",
       "2024-07-26       1  1.755746       1.341485   -1.004953  ...  2.633200   \n",
       "2024-07-29       0  1.755746       1.341485   -1.004953  ...  2.633200   \n",
       "\n",
       "                  GDP       GVZ       OVX      VVIX  RSI (14D)  20 Day CCI  \\\n",
       "Date                                                                         \n",
       "2009-09-18  14448.882  1.117324  0.270120 -1.493092   1.482107    0.984329   \n",
       "2009-09-21  14448.882  1.243262  0.254290 -1.455507   1.539945    0.832566   \n",
       "2009-09-22  14448.882  1.518226  0.194489 -1.624331   1.632955    0.820504   \n",
       "2009-09-23  14448.882  1.402783  0.244323 -1.629260   1.163946    0.667434   \n",
       "2009-09-24  14448.882  0.987189  0.423140 -1.469062   0.497239    0.276534   \n",
       "...               ...       ...       ...       ...        ...         ...   \n",
       "2024-07-23  28629.153 -0.389731 -0.605202 -0.376635  -0.304872   -0.509211   \n",
       "2024-07-24  28629.153 -0.276387 -0.598753  0.708398  -1.463285   -1.774386   \n",
       "2024-07-25  28629.153 -0.368741 -0.619859  0.601189  -1.677050   -2.058419   \n",
       "2024-07-26  28629.153 -0.440106 -0.427558 -0.000786  -1.293841   -1.693177   \n",
       "2024-07-29  28629.153 -0.440106 -0.427558 -0.000786  -1.070572   -1.422687   \n",
       "\n",
       "            Williams %R  EMA (5D)      MA50  \n",
       "Date                                         \n",
       "2009-09-18     1.006778 -1.180615 -1.208577  \n",
       "2009-09-21     1.066556 -1.178910 -1.206776  \n",
       "2009-09-22     1.069644 -1.177134 -1.205111  \n",
       "2009-09-23     0.589041 -1.177101 -1.203546  \n",
       "2009-09-24     0.107400 -1.178920 -1.202392  \n",
       "...                 ...       ...       ...  \n",
       "2024-07-23    -1.056645  2.504898  2.447403  \n",
       "2024-07-24    -1.987103  2.453630  2.452126  \n",
       "2024-07-25    -1.766556  2.407028  2.455868  \n",
       "2024-07-26    -1.422492  2.389579  2.459861  \n",
       "2024-07-29    -1.213430  2.386223  2.463269  \n",
       "\n",
       "[3739 rows x 29 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "\n",
    "root = tk.Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "\n",
    "# feature engineering and scaling\n",
    "def prep(dataset):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    macro_path1 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\IRP DATASET  - Copy of US_macroeconomics.csv\"\n",
    "    macro_path2 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\^VIX.csv\"\n",
    "    macro_path3 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\CORESTICKM159SFRBATL.csv\"\n",
    "    macro_path4 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\FFR.csv\"\n",
    "    macro_path5 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\GDP.csv\"\n",
    "    macro_path6 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\VIX9D_History.csv\"\n",
    "    macro_path7 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\GVZ_History.csv\"\n",
    "    macro_path8 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\OVX_History.csv\"\n",
    "    macro_path9 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\VVIX_History.csv\"\n",
    "    macro_data1 = pd.read_csv(macro_path1)\n",
    "    macro_data2 = pd.read_csv(macro_path2)\n",
    "    macro_data3 = pd.read_csv(macro_path3)\n",
    "    macro_data4 = pd.read_csv(macro_path4)\n",
    "    macro_data5 = pd.read_csv(macro_path5)\n",
    "    macro_data6 = pd.read_csv(macro_path6)\n",
    "    macro_data7 = pd.read_csv(macro_path7)\n",
    "    macro_data8 = pd.read_csv(macro_path8)\n",
    "    macro_data9 = pd.read_csv(macro_path9)\n",
    "\n",
    "    dataset['Date'] = pd.to_datetime(dataset['Date'], dayfirst=True)\n",
    "    dataset.set_index('Date', inplace=True)\n",
    "    dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "\n",
    "    macro_data1['date'] = pd.to_datetime(macro_data1['date'], dayfirst=True)\n",
    "    macro_data1.set_index('date', inplace=True)\n",
    "\n",
    "    macro_data2['Date'] = pd.to_datetime(macro_data2['Date'], dayfirst=True)\n",
    "    macro_data2.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data3['Date'] = pd.to_datetime(macro_data3['Date'], dayfirst=True)\n",
    "    macro_data3.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data4['Date'] = pd.to_datetime(macro_data4['Date'], dayfirst=True)\n",
    "    macro_data4.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data5['Date'] = pd.to_datetime(macro_data5['Date'], dayfirst=True)\n",
    "    macro_data5.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data7['Date'] = pd.to_datetime(macro_data7['Date'], dayfirst=False)\n",
    "    macro_data7.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data8['Date'] = pd.to_datetime(macro_data8['Date'], dayfirst=False)\n",
    "    macro_data8.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data9['Date'] = pd.to_datetime(macro_data9['Date'])\n",
    "    macro_data9.set_index('Date', inplace=True)\n",
    "\n",
    "    merge_data1 = dataset.join(macro_data1, how='left').fillna(method='ffill')\n",
    "    merge_data2 = merge_data1.join(macro_data2, how='left').fillna(method='ffill')\n",
    "    merge_data3 = merge_data2.join(macro_data3, how='left').fillna(method='ffill')\n",
    "    merge_data4 = merge_data3.join(macro_data4, how='left').fillna(method='ffill')\n",
    "    merge_data5 = merge_data4.join(macro_data5, how='left').fillna(method='ffill')\n",
    "    merge_data7 = merge_data5.join(macro_data7, how='left').fillna(method='ffill')\n",
    "    merge_data8 = merge_data7.join(macro_data8, how='left').fillna(method='ffill')\n",
    "    merge_final = merge_data8.join(macro_data9, how='left').fillna(method='ffill')\n",
    "\n",
    "    merge_final['RSI (14D)'] = ta.rsi(merge_final['Close'], length=14)\n",
    "    merge_final['20 Day CCI'] = ta.cci(high=merge_final['High'], low=merge_final['Low'], \n",
    "                                    close=merge_final['Close'], length=20)\n",
    "    merge_final['Williams %R'] = ta.willr(high=merge_final['High'], low=merge_final['Low'], \n",
    "                                        close=merge_final['Close'], length=14)\n",
    "    merge_final['EMA (5D)'] = merge_final['Close'].ewm(span=5, adjust=False).mean()\n",
    "    merge_final['MA50'] = merge_final['Close'].rolling(window=50).mean()\n",
    "\n",
    "    final_dataset = merge_final.dropna()\n",
    "\n",
    "    time_shifted = final_dataset#.resample('W-FRI').asfreq().dropna()\n",
    "    \n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CPI', \n",
    "                'Mortgage_rate', 'Unemp_rate', 'disposable_income','GVZ', 'OVX', 'VVIX', \n",
    "                'RSI (14D)', '20 Day CCI', 'Williams %R', 'EMA (5D)', 'MA50', 'DFF']\n",
    "    \n",
    "    time_shifted[features] = time_shifted[features].astype(float)\n",
    "    time_shifted[features] = scaler.fit_transform(time_shifted[features])\n",
    "\n",
    "    return time_shifted, scaler\n",
    "\n",
    "# get dataset\n",
    "file_path = filedialog.askopenfilename(parent=root, title=\"Select A File\")\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1 loss: 0.7155\n",
      "Epoch 26 loss: 0.6799\n",
      "Epoch 51 loss: 0.7080\n",
      "Epoch 76 loss: 0.7167\n",
      "Epoch 101 loss: 0.7027\n",
      "Epoch 126 loss: 0.6873\n",
      "\n",
      "Accuracy: 0.5280\n",
      "Precision: 0.5280\n",
      "Recall: 1.0000\n",
      "F1: 0.6911\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 2\n",
      "Epoch 1 loss: 0.6992\n",
      "Epoch 26 loss: 0.6901\n",
      "Epoch 51 loss: 0.6609\n",
      "Epoch 76 loss: 0.7445\n",
      "Epoch 101 loss: 0.7472\n",
      "Epoch 126 loss: 0.6651\n",
      "\n",
      "Accuracy: 0.5575\n",
      "Precision: 0.5575\n",
      "Recall: 1.0000\n",
      "F1: 0.7159\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 3\n",
      "Epoch 1 loss: 0.6664\n",
      "Epoch 26 loss: 0.6811\n",
      "Epoch 51 loss: 0.6711\n",
      "Epoch 76 loss: 0.6970\n",
      "Epoch 101 loss: 0.6654\n",
      "Epoch 126 loss: 0.7154\n",
      "\n",
      "Accuracy: 0.5841\n",
      "Precision: 0.5841\n",
      "Recall: 1.0000\n",
      "F1: 0.7374\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 4\n",
      "Epoch 1 loss: 0.6914\n",
      "Epoch 26 loss: 0.6370\n",
      "Epoch 51 loss: 0.7045\n",
      "Epoch 76 loss: 0.6603\n",
      "Epoch 101 loss: 0.7243\n",
      "Epoch 126 loss: 0.6569\n",
      "\n",
      "Accuracy: 0.5015\n",
      "Precision: 0.5015\n",
      "Recall: 1.0000\n",
      "F1: 0.6680\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 5\n",
      "Epoch 1 loss: 0.7081\n",
      "Epoch 26 loss: 0.6539\n",
      "Epoch 51 loss: 0.6984\n",
      "Epoch 76 loss: 0.6665\n",
      "Epoch 101 loss: 0.7309\n",
      "Epoch 126 loss: 0.7231\n",
      "\n",
      "Accuracy: 0.4012\n",
      "Precision: 0.7500\n",
      "Recall: 0.0146\n",
      "F1: 0.0287\n",
      "Kappa: 0.0057\n",
      "\n",
      "Fold 6\n",
      "Epoch 1 loss: 0.7546\n",
      "Epoch 26 loss: 0.7077\n",
      "Epoch 51 loss: 0.6553\n",
      "Epoch 76 loss: 0.6229\n",
      "Epoch 101 loss: 0.6682\n",
      "Epoch 126 loss: 0.6749\n",
      "\n",
      "Accuracy: 0.5487\n",
      "Precision: 0.5487\n",
      "Recall: 1.0000\n",
      "F1: 0.7086\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 7\n",
      "Epoch 1 loss: 0.6259\n",
      "Epoch 26 loss: 0.7228\n",
      "Epoch 51 loss: 0.6782\n",
      "Epoch 76 loss: 0.8281\n",
      "Epoch 101 loss: 0.5853\n",
      "Epoch 126 loss: 0.7697\n",
      "\n",
      "Accuracy: 0.5929\n",
      "Precision: 0.5929\n",
      "Recall: 1.0000\n",
      "F1: 0.7444\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 8\n",
      "Epoch 1 loss: 0.6711\n",
      "Epoch 26 loss: 0.6802\n",
      "Epoch 51 loss: 0.6480\n",
      "Epoch 76 loss: 0.6694\n",
      "Epoch 101 loss: 0.6583\n",
      "Epoch 126 loss: 0.6693\n",
      "\n",
      "Accuracy: 0.5841\n",
      "Precision: 0.5841\n",
      "Recall: 1.0000\n",
      "F1: 0.7374\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 9\n",
      "Epoch 1 loss: 0.6444\n",
      "Epoch 26 loss: 0.7607\n",
      "Epoch 51 loss: 0.6392\n",
      "Epoch 76 loss: 0.6650\n",
      "Epoch 101 loss: 0.6880\n",
      "Epoch 126 loss: 0.6903\n",
      "\n",
      "Accuracy: 0.4661\n",
      "Precision: 0.4661\n",
      "Recall: 1.0000\n",
      "F1: 0.6358\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 10\n",
      "Epoch 1 loss: 0.6820\n",
      "Epoch 26 loss: 0.6989\n",
      "Epoch 51 loss: 0.6681\n",
      "Epoch 76 loss: 0.6611\n",
      "Epoch 101 loss: 0.6869\n",
      "Epoch 126 loss: 0.6840\n",
      "\n",
      "Accuracy: 0.4631\n",
      "Precision: 0.5738\n",
      "Recall: 0.1832\n",
      "F1: 0.2778\n",
      "Kappa: 0.0069\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.5227\n",
      "Average Precision: 0.5687\n",
      "Average Recall: 0.8198\n",
      "Average F1: 0.5945\n",
      "Average Kappa: 0.0013\n"
     ]
    }
   ],
   "source": [
    "# create LSTM model class\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer, num_layers=4, dropout=0.3):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers with dropout\n",
    "        self.lstm = nn.LSTM(input_layer, hidden_layer, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Linear layer\n",
    "        self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, input_tensor.size(0), self.hidden_layer).to(input_tensor.device)\n",
    "        c0 = torch.zeros(self.num_layers, input_tensor.size(0), self.hidden_layer).to(input_tensor.device)\n",
    "        \n",
    "        # Pass through LSTM layers\n",
    "        out, _ = self.lstm(input_tensor, (h0, c0))\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Pass through linear layer\n",
    "        out = self.linear_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(0, len(input_data) - sequence_length):\n",
    "        sequence = input_data[i : i + sequence_length, :-1]\n",
    "        label = input_data[i + sequence_length, -1]\n",
    "        sequences.append((sequence, label))\n",
    "    return sequences\n",
    "\n",
    "# train the model with data provided\n",
    "def trainer(model, train_data, loss_func, opt, epochs, fold, losses):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for sequence, labels in train_data:\n",
    "            opt.zero_grad()\n",
    "            sequence = sequence.clone().detach().float()\n",
    "            labels = labels.clone().detach().float().view(-1, 1)\n",
    "            \n",
    "            y = model(sequence)\n",
    "            loss = loss_func(y, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if epoch % 25 == 1:\n",
    "            print(f'Epoch {epoch} loss: {loss.item():.4f}')\n",
    "\n",
    "            new_row = pd.DataFrame({'Fold': [fold+1], 'Epoch': [epoch], 'Loss': [loss.item()]})\n",
    "            losses = pd.concat([losses, new_row], ignore_index=True)\n",
    "            \n",
    "    return losses\n",
    "\n",
    "def predictor(model, test_data):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for sequence, _ in test_data:\n",
    "            sequence = sequence.clone().detach().float()\n",
    "            y = model(sequence)\n",
    "            batch_predictions = torch.sigmoid(y)\n",
    "\n",
    "            # Convert predictions to tensor if they are scalar or float\n",
    "            if isinstance(batch_predictions, float) or batch_predictions.ndimension() == 0:\n",
    "                batch_predictions = torch.tensor([batch_predictions])\n",
    "\n",
    "            batch_predictions = torch.round(batch_predictions)\n",
    "\n",
    "            predictions.extend(batch_predictions.squeeze().tolist())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# create sequences\n",
    "sequence_length = 10\n",
    "sequences = create_sequence(ticker[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CPI', \n",
    "                                    'RSI (14D)', '20 Day CCI', 'Williams %R', 'EMA (5D)', 'MA50', 'Target']].values, sequence_length)\n",
    "\n",
    "# cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "kappas = []\n",
    "losses = pd.DataFrame(columns=['Fold', 'Epoch', 'Loss'])\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(sequences)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    \n",
    "    train_sequences = [sequences[i] for i in train_index]\n",
    "    test_sequences = [sequences[i] for i in test_index]\n",
    "    \n",
    "    train_data = torch.utils.data.DataLoader(train_sequences, shuffle=True, batch_size=32)\n",
    "    test_data = torch.utils.data.DataLoader(test_sequences, shuffle=False, batch_size=32)\n",
    "    \n",
    "    # initialize model\n",
    "    model = LSTM_Model(input_layer=12, hidden_layer=10, output_layer=1)\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    # train model\n",
    "    epochs = 150\n",
    "    losses = trainer(model, train_data, loss_func, opt, epochs, fold, losses)\n",
    "    \n",
    "    # make predictions\n",
    "    test_labels = [label for _, label in test_sequences]\n",
    "    predictions = predictor(model, test_data)\n",
    "    \n",
    "    # calculate statistics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    kappa = cohen_kappa_score(test_labels, predictions)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    kappas.append(kappa)\n",
    "    \n",
    "    print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1: {f1:.4f}')\n",
    "    print(f'Kappa: {kappa:.4f}\\n')\n",
    "\n",
    "# average scores across all folds\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_f1 = np.mean(f1s)\n",
    "avg_kappa = np.mean(kappas)\n",
    "\n",
    "print(f'\\nCross-Validation Results:')\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1: {avg_f1:.4f}')\n",
    "print(f'Average Kappa: {avg_kappa:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days rising: 2080\n",
      "Number of days falling: 1659\n",
      "Rise % is: 55.63%\n",
      "Fall % is: 44.37%\n"
     ]
    }
   ],
   "source": [
    "fall = (ticker.Target == 0).sum()\n",
    "rise = (ticker.Target == 1).sum()\n",
    "\n",
    "rise_per = (rise / (rise + fall)) * 100\n",
    "fall_per = (fall / (rise + fall)) * 100\n",
    "\n",
    "print(f'Number of days rising: {rise}')\n",
    "print(f'Number of days falling: {fall}')\n",
    "\n",
    "print(f'Rise % is: {rise_per:.2f}%')\n",
    "print(f'Fall % is: {fall_per:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1</th>\n",
       "      <th>Average Kappa</th>\n",
       "      <th>Number of Rises</th>\n",
       "      <th>Number of Falls</th>\n",
       "      <th>Rise %</th>\n",
       "      <th>Fall %</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>^IXIC (3)_Monthly</th>\n",
       "      <td>0.522714</td>\n",
       "      <td>0.56866</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.594518</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>2080</td>\n",
       "      <td>1659</td>\n",
       "      <td>55.629848</td>\n",
       "      <td>44.370152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.679867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.707950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0.716684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0.698931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.668088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>76</td>\n",
       "      <td>0.661077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>0.686948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "      <td>0.684031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Average Accuracy  Average Precision  Average Recall  \\\n",
       "Dataset                                                                  \n",
       "^IXIC (3)_Monthly          0.522714            0.56866        0.819788   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "...                             ...                ...             ...   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "NaN                             NaN                NaN             NaN   \n",
       "\n",
       "                   Average F1  Average Kappa Number of Rises Number of Falls  \\\n",
       "Dataset                                                                        \n",
       "^IXIC (3)_Monthly    0.594518       0.001258            2080            1659   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "...                       ...            ...             ...             ...   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "NaN                       NaN            NaN             NaN             NaN   \n",
       "\n",
       "                      Rise %     Fall % Fold Epoch      Loss  \n",
       "Dataset                                                       \n",
       "^IXIC (3)_Monthly  55.629848  44.370152  NaN   NaN       NaN  \n",
       "NaN                      NaN        NaN    1     1  0.715501  \n",
       "NaN                      NaN        NaN    1    26  0.679867  \n",
       "NaN                      NaN        NaN    1    51  0.707950  \n",
       "NaN                      NaN        NaN    1    76  0.716684  \n",
       "...                      ...        ...  ...   ...       ...  \n",
       "NaN                      NaN        NaN   10    26  0.698931  \n",
       "NaN                      NaN        NaN   10    51  0.668088  \n",
       "NaN                      NaN        NaN   10    76  0.661077  \n",
       "NaN                      NaN        NaN   10   101  0.686948  \n",
       "NaN                      NaN        NaN   10   126  0.684031  \n",
       "\n",
       "[61 rows x 12 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Dataset', 'Average Accuracy', 'Average Precision', \n",
    "                                'Average Recall', 'Average F1', 'Average Kappa', 'Number of Rises', \n",
    "                                'Number of Falls', 'Rise %', 'Fall %'])\n",
    "\n",
    "datatset_name = (file_path.split('/')[-1].split('.')[0] + '_Monthly')\n",
    "\n",
    "metrics = {'Dataset': datatset_name ,'Average Accuracy': avg_accuracy, \n",
    "           'Average Precision': avg_precision, 'Average Recall': avg_recall, \n",
    "           'Average F1': avg_f1, 'Average Kappa': avg_kappa, 'Number of Rises': rise, 'Number of Falls': fall, \n",
    "           'Rise %': rise_per, 'Fall %': fall_per}\n",
    "\n",
    "export_results = results._append(metrics, ignore_index=True)\n",
    "\n",
    "export_results = pd.concat([export_results, losses], ignore_index=True)\n",
    "\n",
    "export_results.set_index('Dataset', inplace=True)\n",
    "\n",
    "export_results.to_csv(r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\IRP DATA\\\\\" + datatset_name + '_daily.csv')\n",
    "\n",
    "export_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
