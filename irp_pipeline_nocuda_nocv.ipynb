{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Mortgage_rate</th>\n",
       "      <th>Unemp_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>DFF</th>\n",
       "      <th>GDP</th>\n",
       "      <th>GVZ</th>\n",
       "      <th>OVX</th>\n",
       "      <th>VVIX</th>\n",
       "      <th>RSI (14D)</th>\n",
       "      <th>20 Day CCI</th>\n",
       "      <th>Williams %R</th>\n",
       "      <th>EMA (5D)</th>\n",
       "      <th>MA50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>-1.534147</td>\n",
       "      <td>-1.544658</td>\n",
       "      <td>-1.556026</td>\n",
       "      <td>-1.547917</td>\n",
       "      <td>-1.547917</td>\n",
       "      <td>2.052240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.707271</td>\n",
       "      <td>1.894013</td>\n",
       "      <td>1.460242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>0.802744</td>\n",
       "      <td>0.461573</td>\n",
       "      <td>-1.512091</td>\n",
       "      <td>0.402979</td>\n",
       "      <td>0.139903</td>\n",
       "      <td>-0.592440</td>\n",
       "      <td>-1.536879</td>\n",
       "      <td>-1.640859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>-1.475801</td>\n",
       "      <td>-1.482245</td>\n",
       "      <td>-1.478456</td>\n",
       "      <td>-1.473350</td>\n",
       "      <td>-1.473350</td>\n",
       "      <td>-0.247923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.662329</td>\n",
       "      <td>1.710351</td>\n",
       "      <td>1.547702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>14651.249</td>\n",
       "      <td>1.754789</td>\n",
       "      <td>0.239545</td>\n",
       "      <td>-0.818309</td>\n",
       "      <td>-0.231220</td>\n",
       "      <td>-0.111108</td>\n",
       "      <td>-0.920169</td>\n",
       "      <td>-1.450523</td>\n",
       "      <td>-1.488785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>-1.406098</td>\n",
       "      <td>-1.421360</td>\n",
       "      <td>-1.415639</td>\n",
       "      <td>-1.435302</td>\n",
       "      <td>-1.435302</td>\n",
       "      <td>-2.236625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.604209</td>\n",
       "      <td>1.672052</td>\n",
       "      <td>1.503972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>14651.249</td>\n",
       "      <td>1.239517</td>\n",
       "      <td>-0.028968</td>\n",
       "      <td>-1.263925</td>\n",
       "      <td>-0.109079</td>\n",
       "      <td>0.400549</td>\n",
       "      <td>0.030069</td>\n",
       "      <td>-1.414042</td>\n",
       "      <td>-1.453645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>-1.316705</td>\n",
       "      <td>-1.330820</td>\n",
       "      <td>-1.317794</td>\n",
       "      <td>-1.327305</td>\n",
       "      <td>-1.327305</td>\n",
       "      <td>0.395996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.603793</td>\n",
       "      <td>1.737335</td>\n",
       "      <td>1.503972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>14651.249</td>\n",
       "      <td>0.118399</td>\n",
       "      <td>-0.392636</td>\n",
       "      <td>-1.094875</td>\n",
       "      <td>0.909172</td>\n",
       "      <td>0.588783</td>\n",
       "      <td>0.550334</td>\n",
       "      <td>-1.322440</td>\n",
       "      <td>-1.430618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>-1.264362</td>\n",
       "      <td>-1.283205</td>\n",
       "      <td>-1.296872</td>\n",
       "      <td>-1.316375</td>\n",
       "      <td>-1.316375</td>\n",
       "      <td>2.106263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.600326</td>\n",
       "      <td>1.964518</td>\n",
       "      <td>1.503972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>0.577313</td>\n",
       "      <td>-0.357636</td>\n",
       "      <td>0.522597</td>\n",
       "      <td>-0.761430</td>\n",
       "      <td>-1.315571</td>\n",
       "      <td>-1.607924</td>\n",
       "      <td>-1.282010</td>\n",
       "      <td>-1.321091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>2.313944</td>\n",
       "      <td>2.302693</td>\n",
       "      <td>2.283023</td>\n",
       "      <td>2.276790</td>\n",
       "      <td>2.276790</td>\n",
       "      <td>0.195369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.820540</td>\n",
       "      <td>-1.583370</td>\n",
       "      <td>-0.201501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23292.362</td>\n",
       "      <td>-0.598151</td>\n",
       "      <td>0.087515</td>\n",
       "      <td>1.050710</td>\n",
       "      <td>0.708475</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>2.278443</td>\n",
       "      <td>2.101319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>2.383814</td>\n",
       "      <td>2.381494</td>\n",
       "      <td>2.413298</td>\n",
       "      <td>2.414856</td>\n",
       "      <td>2.414856</td>\n",
       "      <td>0.157269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.113773</td>\n",
       "      <td>-1.731344</td>\n",
       "      <td>-0.245232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>23292.362</td>\n",
       "      <td>-0.318374</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.882336</td>\n",
       "      <td>-0.060083</td>\n",
       "      <td>-0.253436</td>\n",
       "      <td>0.520338</td>\n",
       "      <td>2.396579</td>\n",
       "      <td>2.406917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>2.494608</td>\n",
       "      <td>2.495961</td>\n",
       "      <td>2.522433</td>\n",
       "      <td>2.518025</td>\n",
       "      <td>2.518025</td>\n",
       "      <td>0.184247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.199010</td>\n",
       "      <td>-1.917617</td>\n",
       "      <td>-0.463882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>23828.973</td>\n",
       "      <td>-0.419014</td>\n",
       "      <td>-0.137248</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.221487</td>\n",
       "      <td>0.505724</td>\n",
       "      <td>0.880479</td>\n",
       "      <td>2.491948</td>\n",
       "      <td>2.477216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>2.301275</td>\n",
       "      <td>2.315756</td>\n",
       "      <td>2.260382</td>\n",
       "      <td>2.246216</td>\n",
       "      <td>2.246216</td>\n",
       "      <td>0.356409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.339801</td>\n",
       "      <td>-1.861909</td>\n",
       "      <td>-0.769993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>23828.973</td>\n",
       "      <td>-0.078854</td>\n",
       "      <td>0.103374</td>\n",
       "      <td>1.645090</td>\n",
       "      <td>-1.626275</td>\n",
       "      <td>-1.440309</td>\n",
       "      <td>-1.256870</td>\n",
       "      <td>2.304144</td>\n",
       "      <td>2.483344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>2.439366</td>\n",
       "      <td>2.428492</td>\n",
       "      <td>2.325603</td>\n",
       "      <td>2.317731</td>\n",
       "      <td>2.317731</td>\n",
       "      <td>2.738055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.638721</td>\n",
       "      <td>-1.570314</td>\n",
       "      <td>-0.988643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>24654.603</td>\n",
       "      <td>0.088207</td>\n",
       "      <td>2.102179</td>\n",
       "      <td>3.304487</td>\n",
       "      <td>-2.526197</td>\n",
       "      <td>-2.584287</td>\n",
       "      <td>-1.969267</td>\n",
       "      <td>2.441447</td>\n",
       "      <td>2.567015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2009-09-30 -1.534147 -1.544658 -1.556026 -1.547917  -1.547917  2.052240   \n",
       "2009-11-30 -1.475801 -1.482245 -1.478456 -1.473350  -1.473350 -0.247923   \n",
       "2009-12-31 -1.406098 -1.421360 -1.415639 -1.435302  -1.435302 -2.236625   \n",
       "2010-03-31 -1.316705 -1.330820 -1.317794 -1.327305  -1.327305  0.395996   \n",
       "2010-04-30 -1.264362 -1.283205 -1.296872 -1.316375  -1.316375  2.106263   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "2021-04-30  2.313944  2.302693  2.283023  2.276790   2.276790  0.195369   \n",
       "2021-06-30  2.383814  2.381494  2.413298  2.414856   2.414856  0.157269   \n",
       "2021-08-31  2.494608  2.495961  2.522433  2.518025   2.518025  0.184247   \n",
       "2021-09-30  2.301275  2.315756  2.260382  2.246216   2.246216  0.356409   \n",
       "2021-11-30  2.439366  2.428492  2.325603  2.317731   2.317731  2.738055   \n",
       "\n",
       "            Target       CPI  Mortgage_rate  Unemp_rate  ...   DFF        GDP  \\\n",
       "Date                                                     ...                    \n",
       "2009-09-30     0.0 -1.707271       1.894013    1.460242  ...  0.07  14448.882   \n",
       "2009-11-30     1.0 -1.662329       1.710351    1.547702  ...  0.13  14651.249   \n",
       "2009-12-31     1.0 -1.604209       1.672052    1.503972  ...  0.05  14651.249   \n",
       "2010-03-31     1.0 -1.603793       1.737335    1.503972  ...  0.09  14651.249   \n",
       "2010-04-30     1.0 -1.600326       1.964518    1.503972  ...  0.20  14980.193   \n",
       "...            ...       ...            ...         ...  ...   ...        ...   \n",
       "2021-04-30     1.0  1.820540      -1.583370   -0.201501  ...  0.05  23292.362   \n",
       "2021-06-30     1.0  2.113773      -1.731344   -0.245232  ...  0.08  23292.362   \n",
       "2021-08-31     1.0  2.199010      -1.917617   -0.463882  ...  0.06  23828.973   \n",
       "2021-09-30     1.0  2.339801      -1.861909   -0.769993  ...  0.06  23828.973   \n",
       "2021-11-30     0.0  2.638721      -1.570314   -0.988643  ...  0.07  24654.603   \n",
       "\n",
       "                 GVZ       OVX      VVIX  RSI (14D)  20 Day CCI  Williams %R  \\\n",
       "Date                                                                           \n",
       "2009-09-30  0.802744  0.461573 -1.512091   0.402979    0.139903    -0.592440   \n",
       "2009-11-30  1.754789  0.239545 -0.818309  -0.231220   -0.111108    -0.920169   \n",
       "2009-12-31  1.239517 -0.028968 -1.263925  -0.109079    0.400549     0.030069   \n",
       "2010-03-31  0.118399 -0.392636 -1.094875   0.909172    0.588783     0.550334   \n",
       "2010-04-30  0.577313 -0.357636  0.522597  -0.761430   -1.315571    -1.607924   \n",
       "...              ...       ...       ...        ...         ...          ...   \n",
       "2021-04-30 -0.598151  0.087515  1.050710   0.708475    0.804812     0.131750   \n",
       "2021-06-30 -0.318374 -0.221466  0.882336  -0.060083   -0.253436     0.520338   \n",
       "2021-08-31 -0.419014 -0.137248  0.820125   0.221487    0.505724     0.880479   \n",
       "2021-09-30 -0.078854  0.103374  1.645090  -1.626275   -1.440309    -1.256870   \n",
       "2021-11-30  0.088207  2.102179  3.304487  -2.526197   -2.584287    -1.969267   \n",
       "\n",
       "            EMA (5D)      MA50  \n",
       "Date                            \n",
       "2009-09-30 -1.536879 -1.640859  \n",
       "2009-11-30 -1.450523 -1.488785  \n",
       "2009-12-31 -1.414042 -1.453645  \n",
       "2010-03-31 -1.322440 -1.430618  \n",
       "2010-04-30 -1.282010 -1.321091  \n",
       "...              ...       ...  \n",
       "2021-04-30  2.278443  2.101319  \n",
       "2021-06-30  2.396579  2.406917  \n",
       "2021-08-31  2.491948  2.477216  \n",
       "2021-09-30  2.304144  2.483344  \n",
       "2021-11-30  2.441447  2.567015  \n",
       "\n",
       "[102 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "\n",
    "root = tk.Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "\n",
    "# feature engineering and scaling\n",
    "def prep(dataset):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    macro_path1 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\IRP DATASET  - Copy of US_macroeconomics.csv\"\n",
    "    macro_path2 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\^VIX.csv\"\n",
    "    macro_path3 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\CORESTICKM159SFRBATL.csv\"\n",
    "    macro_path4 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\FFR.csv\"\n",
    "    macro_path5 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\GDP.csv\"\n",
    "    macro_path6 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\VIX9D_History.csv\"\n",
    "    macro_path7 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\GVZ_History.csv\"\n",
    "    macro_path8 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\OVX_History.csv\"\n",
    "    macro_path9 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\VVIX_History.csv\"\n",
    "    macro_data1 = pd.read_csv(macro_path1)\n",
    "    macro_data2 = pd.read_csv(macro_path2)\n",
    "    macro_data3 = pd.read_csv(macro_path3)\n",
    "    macro_data4 = pd.read_csv(macro_path4)\n",
    "    macro_data5 = pd.read_csv(macro_path5)\n",
    "    macro_data6 = pd.read_csv(macro_path6)\n",
    "    macro_data7 = pd.read_csv(macro_path7)\n",
    "    macro_data8 = pd.read_csv(macro_path8)\n",
    "    macro_data9 = pd.read_csv(macro_path9)\n",
    "\n",
    "    dataset['Date'] = pd.to_datetime(dataset['Date'], dayfirst=True)\n",
    "    dataset.set_index('Date', inplace=True)\n",
    "    dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "\n",
    "    macro_data1['date'] = pd.to_datetime(macro_data1['date'], dayfirst=True)\n",
    "    macro_data1.set_index('date', inplace=True)\n",
    "\n",
    "    macro_data2['Date'] = pd.to_datetime(macro_data2['Date'], dayfirst=True)\n",
    "    macro_data2.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data3['Date'] = pd.to_datetime(macro_data3['Date'], dayfirst=True)\n",
    "    macro_data3.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data4['Date'] = pd.to_datetime(macro_data4['Date'], dayfirst=True)\n",
    "    macro_data4.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data5['Date'] = pd.to_datetime(macro_data5['Date'], dayfirst=True)\n",
    "    macro_data5.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data7['Date'] = pd.to_datetime(macro_data7['Date'], dayfirst=False)\n",
    "    macro_data7.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data8['Date'] = pd.to_datetime(macro_data8['Date'], dayfirst=False)\n",
    "    macro_data8.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data9['Date'] = pd.to_datetime(macro_data9['Date'])\n",
    "    macro_data9.set_index('Date', inplace=True)\n",
    "\n",
    "    merge_data1 = dataset.join(macro_data1, how='left').fillna(method='ffill')\n",
    "    merge_data2 = merge_data1.join(macro_data2, how='left').fillna(method='ffill')\n",
    "    merge_data3 = merge_data2.join(macro_data3, how='left').fillna(method='ffill')\n",
    "    merge_data4 = merge_data3.join(macro_data4, how='left').fillna(method='ffill')\n",
    "    merge_data5 = merge_data4.join(macro_data5, how='left').fillna(method='ffill')\n",
    "    merge_data7 = merge_data5.join(macro_data7, how='left').fillna(method='ffill')\n",
    "    merge_data8 = merge_data7.join(macro_data8, how='left').fillna(method='ffill')\n",
    "    merge_final = merge_data8.join(macro_data9, how='left').fillna(method='ffill')\n",
    "\n",
    "    merge_final['RSI (14D)'] = ta.rsi(merge_final['Close'], length=14)\n",
    "    merge_final['20 Day CCI'] = ta.cci(high=merge_final['High'], low=merge_final['Low'], \n",
    "                                    close=merge_final['Close'], length=20)\n",
    "    merge_final['Williams %R'] = ta.willr(high=merge_final['High'], low=merge_final['Low'], \n",
    "                                        close=merge_final['Close'], length=14)\n",
    "    merge_final['EMA (5D)'] = merge_final['Close'].ewm(span=5, adjust=False).mean()\n",
    "    merge_final['MA50'] = merge_final['Close'].rolling(window=50).mean()\n",
    "\n",
    "    final_dataset = merge_final.dropna()\n",
    "\n",
    "    time_shifted = final_dataset.resample('M').asfreq().dropna()\n",
    "\n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CPI', \n",
    "                'Mortgage_rate', 'Unemp_rate', 'disposable_income','GVZ', 'OVX', 'VVIX', \n",
    "                'RSI (14D)', '20 Day CCI', 'Williams %R', 'EMA (5D)', 'MA50',]\n",
    "    \n",
    "    time_shifted[features] = time_shifted[features].astype(float)\n",
    "    time_shifted[features] = scaler.fit_transform(time_shifted[features])\n",
    "\n",
    "    return time_shifted, scaler\n",
    "\n",
    "# get dataset\n",
    "file_path = filedialog.askopenfilename(parent=root, title=\"Select A File\")\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1 loss: 0.7096\n",
      "Epoch 26 loss: 0.6896\n",
      "Epoch 51 loss: 0.7008\n",
      "Epoch 76 loss: 0.6812\n",
      "Epoch 101 loss: 0.6704\n",
      "Epoch 126 loss: 0.5633\n",
      "\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "F1: 0.6667\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 2\n",
      "Epoch 1 loss: 0.6996\n",
      "Epoch 26 loss: 0.6999\n",
      "Epoch 51 loss: 0.7049\n",
      "Epoch 76 loss: 0.6751\n",
      "Epoch 101 loss: 0.6853\n",
      "Epoch 126 loss: 0.6766\n",
      "\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "F1: 0.6667\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 3\n",
      "Epoch 1 loss: 0.6934\n",
      "Epoch 26 loss: 0.6882\n",
      "Epoch 51 loss: 0.6669\n",
      "Epoch 76 loss: 0.6977\n",
      "Epoch 101 loss: 0.6855\n",
      "Epoch 126 loss: 0.6857\n",
      "\n",
      "Accuracy: 0.6250\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 4\n",
      "Epoch 1 loss: 0.7021\n",
      "Epoch 26 loss: 0.8657\n",
      "Epoch 51 loss: 0.7508\n",
      "Epoch 76 loss: 0.7549\n",
      "Epoch 101 loss: 0.6863\n",
      "Epoch 126 loss: 0.7036\n",
      "\n",
      "Accuracy: 0.6250\n",
      "Precision: 0.7500\n",
      "Recall: 0.6000\n",
      "F1: 0.6667\n",
      "Kappa: 0.2500\n",
      "\n",
      "Fold 5\n",
      "Epoch 1 loss: 0.7354\n",
      "Epoch 26 loss: 0.7245\n",
      "Epoch 51 loss: 0.6754\n",
      "Epoch 76 loss: 0.6928\n",
      "Epoch 101 loss: 0.6318\n",
      "Epoch 126 loss: 0.6975\n",
      "\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "F1: 0.6667\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 6\n",
      "Epoch 1 loss: 0.7255\n",
      "Epoch 26 loss: 0.6860\n",
      "Epoch 51 loss: 0.6891\n",
      "Epoch 76 loss: 0.7493\n",
      "Epoch 101 loss: 0.6501\n",
      "Epoch 126 loss: 0.4874\n",
      "\n",
      "Accuracy: 0.2500\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 7\n",
      "Epoch 1 loss: 0.7052\n",
      "Epoch 26 loss: 0.6737\n",
      "Epoch 51 loss: 0.7010\n",
      "Epoch 76 loss: 0.7041\n",
      "Epoch 101 loss: 0.6079\n",
      "Epoch 126 loss: 0.5438\n",
      "\n",
      "Accuracy: 0.6250\n",
      "Precision: 1.0000\n",
      "Recall: 0.2500\n",
      "F1: 0.4000\n",
      "Kappa: 0.2500\n",
      "\n",
      "Fold 8\n",
      "Epoch 1 loss: 0.6662\n",
      "Epoch 26 loss: 0.7000\n",
      "Epoch 51 loss: 0.7201\n",
      "Epoch 76 loss: 0.5707\n",
      "Epoch 101 loss: 0.6449\n",
      "Epoch 126 loss: 0.8312\n",
      "\n",
      "Accuracy: 0.7500\n",
      "Precision: 0.8000\n",
      "Recall: 0.8000\n",
      "F1: 0.8000\n",
      "Kappa: 0.4667\n",
      "\n",
      "Fold 9\n",
      "Epoch 1 loss: 0.6929\n",
      "Epoch 26 loss: 0.7135\n",
      "Epoch 51 loss: 0.6552\n",
      "Epoch 76 loss: 0.5219\n",
      "Epoch 101 loss: 0.7909\n",
      "Epoch 126 loss: 0.6540\n",
      "\n",
      "Accuracy: 0.6250\n",
      "Precision: 0.8000\n",
      "Recall: 0.6667\n",
      "F1: 0.7273\n",
      "Kappa: 0.1429\n",
      "\n",
      "Fold 10\n",
      "Epoch 1 loss: 0.6884\n",
      "Epoch 26 loss: 0.7240\n",
      "Epoch 51 loss: 0.6146\n",
      "Epoch 76 loss: 0.4754\n",
      "Epoch 101 loss: 0.6218\n",
      "Epoch 126 loss: 0.5762\n",
      "\n",
      "Accuracy: 0.7500\n",
      "Precision: 0.7500\n",
      "Recall: 1.0000\n",
      "F1: 0.8571\n",
      "Kappa: 0.0000\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.5750\n",
      "Average Precision: 0.5600\n",
      "Average Recall: 0.6317\n",
      "Average F1: 0.5451\n",
      "Average Kappa: 0.1110\n"
     ]
    }
   ],
   "source": [
    "# create LSTM model class\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer, num_layers=4, dropout=0.3):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers with dropout\n",
    "        self.lstm = nn.LSTM(input_layer, hidden_layer, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Linear layer\n",
    "        self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, input_tensor.size(0), self.hidden_layer).to(input_tensor.device)\n",
    "        c0 = torch.zeros(self.num_layers, input_tensor.size(0), self.hidden_layer).to(input_tensor.device)\n",
    "        \n",
    "        # Pass through LSTM layers\n",
    "        out, _ = self.lstm(input_tensor, (h0, c0))\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Pass through linear layer\n",
    "        out = self.linear_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(0, len(input_data) - sequence_length):\n",
    "        sequence = input_data[i : i + sequence_length, :-1]\n",
    "        label = input_data[i + sequence_length, -1]\n",
    "        sequences.append((sequence, label))\n",
    "    return sequences\n",
    "\n",
    "# train the model with data provided\n",
    "def trainer(model, train_data, loss_func, opt, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for sequence, labels in train_data:\n",
    "            opt.zero_grad()\n",
    "            sequence = sequence.clone().detach().float()\n",
    "            labels = labels.clone().detach().float().view(-1, 1)\n",
    "\n",
    "            y = model(sequence)\n",
    "            loss = loss_func(y, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if epoch % 25 == 1:\n",
    "            print(f'Epoch {epoch} loss: {loss.item():.4f}')\n",
    "\n",
    "def predictor(model, test_data):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for sequence, _ in test_data:\n",
    "            sequence = sequence.clone().detach().float()\n",
    "            y = model(sequence)\n",
    "            batch_predictions = torch.sigmoid(y)\n",
    "\n",
    "            # Convert predictions to tensor if they are scalar or float\n",
    "            if isinstance(batch_predictions, float) or batch_predictions.ndimension() == 0:\n",
    "                batch_predictions = torch.tensor([batch_predictions])\n",
    "\n",
    "            batch_predictions = torch.round(batch_predictions)\n",
    "\n",
    "            predictions.extend(batch_predictions.squeeze().tolist())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# create sequences\n",
    "sequence_length = 10\n",
    "sequences = create_sequence(ticker[['Volume', 'CPI', 'Mortgage_rate', 'disposable_income','GVZ', 'OVX', 'VVIX', 'RSI (14D)', \n",
    "                                    '20 Day CCI', 'Williams %R', 'EMA (5D)', 'MA50', 'Target']].values, sequence_length)\n",
    "\n",
    "# cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "kappas = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(sequences)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    \n",
    "    train_sequences = [sequences[i] for i in train_index]\n",
    "    test_sequences = [sequences[i] for i in test_index]\n",
    "    \n",
    "    train_data = torch.utils.data.DataLoader(train_sequences, shuffle=True, batch_size=32)\n",
    "    test_data = torch.utils.data.DataLoader(test_sequences, shuffle=False, batch_size=32)\n",
    "    \n",
    "    # initialize model\n",
    "    model = LSTM_Model(input_layer=12, hidden_layer=10, output_layer=1)\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    # train model\n",
    "    epochs = 150\n",
    "    trainer(model, train_data, loss_func, opt, epochs)\n",
    "    \n",
    "    # make predictions\n",
    "    test_labels = [label for _, label in test_sequences]\n",
    "    predictions = predictor(model, test_data)\n",
    "    \n",
    "    # calculate statistics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    kappa = cohen_kappa_score(test_labels, predictions)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    kappas.append(kappa)\n",
    "    \n",
    "    print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1: {f1:.4f}')\n",
    "    print(f'Kappa: {kappa:.4f}\\n')\n",
    "\n",
    "# average scores across all folds\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_f1 = np.mean(f1s)\n",
    "avg_kappa = np.mean(kappas)\n",
    "\n",
    "print(f'\\nCross-Validation Results:')\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1: {avg_f1:.4f}')\n",
    "print(f'Average Kappa: {avg_kappa:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days rising: 334\n",
      "Number of days falling: 308\n",
      "Rise % is: 52.02%\n",
      "Fall % is: 47.98%\n"
     ]
    }
   ],
   "source": [
    "fall = (ticker.Target == 0).sum()\n",
    "rise = (ticker.Target == 1).sum()\n",
    "\n",
    "print(f'Number of days rising: {rise}')\n",
    "print(f'Number of days falling: {fall}')\n",
    "\n",
    "print(f'Rise % is: {(rise / (rise + fall)) * 100:.2f}%')\n",
    "print(f'Fall % is: {(fall / (rise + fall)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1</th>\n",
       "      <th>Average Kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>^NYA_Monthly</th>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.542963</td>\n",
       "      <td>0.463888</td>\n",
       "      <td>0.40118</td>\n",
       "      <td>-0.032521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average Accuracy  Average Precision  Average Recall  Average F1  \\\n",
       "Dataset                                                                         \n",
       "^NYA_Monthly          0.482456           0.542963        0.463888     0.40118   \n",
       "\n",
       "              Average Kappa  \n",
       "Dataset                      \n",
       "^NYA_Monthly      -0.032521  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Dataset', 'Average Accuracy', 'Average Precision', \n",
    "                                'Average Recall', 'Average F1', 'Average Kappa'])\n",
    "\n",
    "datatset_name = (file_path.split('/')[-1].split('.')[0] + '_Monthly')\n",
    "\n",
    "metrics = {'Dataset': datatset_name ,'Average Accuracy': avg_accuracy, \n",
    "           'Average Precision': avg_precision, 'Average Recall': avg_recall, \n",
    "           'Average F1': avg_f1, 'Average Kappa': avg_kappa}\n",
    "\n",
    "export_results = results._append(metrics, ignore_index=True)\n",
    "\n",
    "export_results.set_index('Dataset', inplace=True)\n",
    "\n",
    "#export_results.to_csv(r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\IRP DATA\\\\\" + datatset_name + '_monthly_w_macro.csv')\n",
    "\n",
    "export_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
