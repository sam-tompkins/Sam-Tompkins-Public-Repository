{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Mortgage_rate</th>\n",
       "      <th>Unemp_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>DFF</th>\n",
       "      <th>GDP</th>\n",
       "      <th>GVZ</th>\n",
       "      <th>OVX</th>\n",
       "      <th>VVIX</th>\n",
       "      <th>RSI (14D)</th>\n",
       "      <th>20 Day CCI</th>\n",
       "      <th>Williams %R</th>\n",
       "      <th>EMA (5D)</th>\n",
       "      <th>MA50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>-1.449132</td>\n",
       "      <td>-1.450485</td>\n",
       "      <td>-1.459087</td>\n",
       "      <td>-1.450291</td>\n",
       "      <td>-1.450291</td>\n",
       "      <td>-0.097305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.481362</td>\n",
       "      <td>1.465477</td>\n",
       "      <td>1.650422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626910</td>\n",
       "      <td>14448.882</td>\n",
       "      <td>0.918290</td>\n",
       "      <td>0.448117</td>\n",
       "      <td>-1.501036</td>\n",
       "      <td>0.318964</td>\n",
       "      <td>0.071242</td>\n",
       "      <td>-0.419260</td>\n",
       "      <td>-1.448028</td>\n",
       "      <td>-1.471599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>-1.382416</td>\n",
       "      <td>-1.381792</td>\n",
       "      <td>-1.381591</td>\n",
       "      <td>-1.375921</td>\n",
       "      <td>-1.375921</td>\n",
       "      <td>-0.400085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.452538</td>\n",
       "      <td>1.302385</td>\n",
       "      <td>1.735954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.589478</td>\n",
       "      <td>14651.249</td>\n",
       "      <td>1.928935</td>\n",
       "      <td>0.209814</td>\n",
       "      <td>-0.798962</td>\n",
       "      <td>0.361834</td>\n",
       "      <td>0.199028</td>\n",
       "      <td>-0.169259</td>\n",
       "      <td>-1.373072</td>\n",
       "      <td>-1.406576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>-1.354372</td>\n",
       "      <td>-1.359499</td>\n",
       "      <td>-1.362671</td>\n",
       "      <td>-1.366138</td>\n",
       "      <td>-1.366138</td>\n",
       "      <td>-0.978751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.415262</td>\n",
       "      <td>1.268375</td>\n",
       "      <td>1.693188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639387</td>\n",
       "      <td>14651.249</td>\n",
       "      <td>1.381947</td>\n",
       "      <td>-0.078379</td>\n",
       "      <td>-1.249904</td>\n",
       "      <td>-0.166639</td>\n",
       "      <td>0.174292</td>\n",
       "      <td>-0.225043</td>\n",
       "      <td>-1.358896</td>\n",
       "      <td>-1.373766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>-1.312220</td>\n",
       "      <td>-1.318296</td>\n",
       "      <td>-1.314175</td>\n",
       "      <td>-1.315750</td>\n",
       "      <td>-1.315750</td>\n",
       "      <td>-0.579279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.414995</td>\n",
       "      <td>1.326346</td>\n",
       "      <td>1.693188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614432</td>\n",
       "      <td>14651.249</td>\n",
       "      <td>0.191822</td>\n",
       "      <td>-0.468702</td>\n",
       "      <td>-1.078834</td>\n",
       "      <td>1.182157</td>\n",
       "      <td>0.585756</td>\n",
       "      <td>0.536860</td>\n",
       "      <td>-1.314783</td>\n",
       "      <td>-1.354016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>-1.281573</td>\n",
       "      <td>-1.284330</td>\n",
       "      <td>-1.294424</td>\n",
       "      <td>-1.297881</td>\n",
       "      <td>-1.297881</td>\n",
       "      <td>-0.186903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.412771</td>\n",
       "      <td>1.528086</td>\n",
       "      <td>1.693188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545807</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>0.678983</td>\n",
       "      <td>-0.431137</td>\n",
       "      <td>0.557969</td>\n",
       "      <td>-0.236542</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>-1.320174</td>\n",
       "      <td>-1.289743</td>\n",
       "      <td>-1.311202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-30</th>\n",
       "      <td>1.588030</td>\n",
       "      <td>1.612084</td>\n",
       "      <td>1.616565</td>\n",
       "      <td>1.634591</td>\n",
       "      <td>1.634591</td>\n",
       "      <td>1.032122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.757019</td>\n",
       "      <td>1.349535</td>\n",
       "      <td>-1.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654622</td>\n",
       "      <td>25994.639</td>\n",
       "      <td>-0.645753</td>\n",
       "      <td>0.105924</td>\n",
       "      <td>-0.447926</td>\n",
       "      <td>2.180331</td>\n",
       "      <td>1.096393</td>\n",
       "      <td>1.375849</td>\n",
       "      <td>1.589292</td>\n",
       "      <td>1.424907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>1.920495</td>\n",
       "      <td>1.918197</td>\n",
       "      <td>1.918103</td>\n",
       "      <td>1.893177</td>\n",
       "      <td>1.893177</td>\n",
       "      <td>1.151787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.757019</td>\n",
       "      <td>1.349535</td>\n",
       "      <td>-1.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654622</td>\n",
       "      <td>25994.639</td>\n",
       "      <td>-0.872240</td>\n",
       "      <td>-0.020271</td>\n",
       "      <td>-0.389762</td>\n",
       "      <td>0.783179</td>\n",
       "      <td>1.057103</td>\n",
       "      <td>0.392954</td>\n",
       "      <td>1.900931</td>\n",
       "      <td>1.783384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>1.989447</td>\n",
       "      <td>1.974935</td>\n",
       "      <td>1.997365</td>\n",
       "      <td>1.992652</td>\n",
       "      <td>1.992652</td>\n",
       "      <td>1.600720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.757019</td>\n",
       "      <td>1.349535</td>\n",
       "      <td>-1.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654622</td>\n",
       "      <td>25994.639</td>\n",
       "      <td>-1.299574</td>\n",
       "      <td>-0.357768</td>\n",
       "      <td>-1.081571</td>\n",
       "      <td>0.743253</td>\n",
       "      <td>0.650498</td>\n",
       "      <td>0.627372</td>\n",
       "      <td>1.992309</td>\n",
       "      <td>1.912835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>1.909996</td>\n",
       "      <td>1.888797</td>\n",
       "      <td>1.879096</td>\n",
       "      <td>1.853864</td>\n",
       "      <td>1.853864</td>\n",
       "      <td>1.119557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.757019</td>\n",
       "      <td>1.349535</td>\n",
       "      <td>-1.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654622</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.570832</td>\n",
       "      <td>-0.782540</td>\n",
       "      <td>-1.319508</td>\n",
       "      <td>-0.844838</td>\n",
       "      <td>-1.283320</td>\n",
       "      <td>1.893125</td>\n",
       "      <td>1.991981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-31</th>\n",
       "      <td>1.886838</td>\n",
       "      <td>1.933463</td>\n",
       "      <td>1.912493</td>\n",
       "      <td>1.956197</td>\n",
       "      <td>1.956197</td>\n",
       "      <td>2.266349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.757019</td>\n",
       "      <td>1.349535</td>\n",
       "      <td>-1.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654622</td>\n",
       "      <td>28629.153</td>\n",
       "      <td>-0.423539</td>\n",
       "      <td>-0.425855</td>\n",
       "      <td>-1.025460</td>\n",
       "      <td>-0.751282</td>\n",
       "      <td>-1.248433</td>\n",
       "      <td>-0.865497</td>\n",
       "      <td>1.958018</td>\n",
       "      <td>2.003302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2009-09-30 -1.449132 -1.450485 -1.459087 -1.450291  -1.450291 -0.097305   \n",
       "2009-11-30 -1.382416 -1.381792 -1.381591 -1.375921  -1.375921 -0.400085   \n",
       "2009-12-31 -1.354372 -1.359499 -1.362671 -1.366138  -1.366138 -0.978751   \n",
       "2010-03-31 -1.312220 -1.318296 -1.314175 -1.315750  -1.315750 -0.579279   \n",
       "2010-04-30 -1.281573 -1.284330 -1.294424 -1.297881  -1.297881 -0.186903   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "2023-11-30  1.588030  1.612084  1.616565  1.634591   1.634591  1.032122   \n",
       "2024-01-31  1.920495  1.918197  1.918103  1.893177   1.893177  1.151787   \n",
       "2024-02-29  1.989447  1.974935  1.997365  1.992652   1.992652  1.600720   \n",
       "2024-04-30  1.909996  1.888797  1.879096  1.853864   1.853864  1.119557   \n",
       "2024-05-31  1.886838  1.933463  1.912493  1.956197   1.956197  2.266349   \n",
       "\n",
       "            Target       CPI  Mortgage_rate  Unemp_rate  ...       DFF  \\\n",
       "Date                                                     ...             \n",
       "2009-09-30     0.0 -1.481362       1.465477    1.650422  ... -0.626910   \n",
       "2009-11-30     1.0 -1.452538       1.302385    1.735954  ... -0.589478   \n",
       "2009-12-31     1.0 -1.415262       1.268375    1.693188  ... -0.639387   \n",
       "2010-03-31     1.0 -1.414995       1.326346    1.693188  ... -0.614432   \n",
       "2010-04-30     1.0 -1.412771       1.528086    1.693188  ... -0.545807   \n",
       "...            ...       ...            ...         ...  ...       ...   \n",
       "2023-11-30     1.0  1.757019       1.349535   -1.001065  ...  2.654622   \n",
       "2024-01-31     1.0  1.757019       1.349535   -1.001065  ...  2.654622   \n",
       "2024-02-29     1.0  1.757019       1.349535   -1.001065  ...  2.654622   \n",
       "2024-04-30     1.0  1.757019       1.349535   -1.001065  ...  2.654622   \n",
       "2024-05-31     0.0  1.757019       1.349535   -1.001065  ...  2.654622   \n",
       "\n",
       "                  GDP       GVZ       OVX      VVIX  RSI (14D)  20 Day CCI  \\\n",
       "Date                                                                         \n",
       "2009-09-30  14448.882  0.918290  0.448117 -1.501036   0.318964    0.071242   \n",
       "2009-11-30  14651.249  1.928935  0.209814 -0.798962   0.361834    0.199028   \n",
       "2009-12-31  14651.249  1.381947 -0.078379 -1.249904  -0.166639    0.174292   \n",
       "2010-03-31  14651.249  0.191822 -0.468702 -1.078834   1.182157    0.585756   \n",
       "2010-04-30  14980.193  0.678983 -0.431137  0.557969  -0.236542   -0.047835   \n",
       "...               ...       ...       ...       ...        ...         ...   \n",
       "2023-11-30  25994.639 -0.645753  0.105924 -0.447926   2.180331    1.096393   \n",
       "2024-01-31  25994.639 -0.872240 -0.020271 -0.389762   0.783179    1.057103   \n",
       "2024-02-29  25994.639 -1.299574 -0.357768 -1.081571   0.743253    0.650498   \n",
       "2024-04-30  28629.153 -0.150046 -0.570832 -0.782540  -1.319508   -0.844838   \n",
       "2024-05-31  28629.153 -0.423539 -0.425855 -1.025460  -0.751282   -1.248433   \n",
       "\n",
       "            Williams %R  EMA (5D)      MA50  \n",
       "Date                                         \n",
       "2009-09-30    -0.419260 -1.448028 -1.471599  \n",
       "2009-11-30    -0.169259 -1.373072 -1.406576  \n",
       "2009-12-31    -0.225043 -1.358896 -1.373766  \n",
       "2010-03-31     0.536860 -1.314783 -1.354016  \n",
       "2010-04-30    -1.320174 -1.289743 -1.311202  \n",
       "...                 ...       ...       ...  \n",
       "2023-11-30     1.375849  1.589292  1.424907  \n",
       "2024-01-31     0.392954  1.900931  1.783384  \n",
       "2024-02-29     0.627372  1.992309  1.912835  \n",
       "2024-04-30    -1.283320  1.893125  1.991981  \n",
       "2024-05-31    -0.865497  1.958018  2.003302  \n",
       "\n",
       "[125 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "\n",
    "root = tk.Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "\n",
    "# feature engineering and scaling\n",
    "def prep(dataset):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    macro_path1 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\IRP DATASET  - Copy of US_macroeconomics.csv\"\n",
    "    macro_path2 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\^VIX.csv\"\n",
    "    macro_path3 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\CORESTICKM159SFRBATL.csv\"\n",
    "    macro_path4 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\FFR.csv\"\n",
    "    macro_path5 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\GDP.csv\"\n",
    "    macro_path6 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\VIX9D_History.csv\"\n",
    "    macro_path7 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\GVZ_History.csv\"\n",
    "    macro_path8 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\OVX_History.csv\"\n",
    "    macro_path9 = r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\raw_data\\VVIX_History.csv\"\n",
    "    macro_data1 = pd.read_csv(macro_path1)\n",
    "    macro_data2 = pd.read_csv(macro_path2)\n",
    "    macro_data3 = pd.read_csv(macro_path3)\n",
    "    macro_data4 = pd.read_csv(macro_path4)\n",
    "    macro_data5 = pd.read_csv(macro_path5)\n",
    "    macro_data6 = pd.read_csv(macro_path6)\n",
    "    macro_data7 = pd.read_csv(macro_path7)\n",
    "    macro_data8 = pd.read_csv(macro_path8)\n",
    "    macro_data9 = pd.read_csv(macro_path9)\n",
    "\n",
    "    dataset['Date'] = pd.to_datetime(dataset['Date'], dayfirst=True)\n",
    "    dataset.set_index('Date', inplace=True)\n",
    "    dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "\n",
    "    macro_data1['date'] = pd.to_datetime(macro_data1['date'], dayfirst=True)\n",
    "    macro_data1.set_index('date', inplace=True)\n",
    "\n",
    "    macro_data2['Date'] = pd.to_datetime(macro_data2['Date'], dayfirst=True)\n",
    "    macro_data2.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data3['Date'] = pd.to_datetime(macro_data3['Date'], dayfirst=True)\n",
    "    macro_data3.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data4['Date'] = pd.to_datetime(macro_data4['Date'], dayfirst=True)\n",
    "    macro_data4.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data5['Date'] = pd.to_datetime(macro_data5['Date'], dayfirst=True)\n",
    "    macro_data5.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data7['Date'] = pd.to_datetime(macro_data7['Date'], dayfirst=False)\n",
    "    macro_data7.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data8['Date'] = pd.to_datetime(macro_data8['Date'], dayfirst=False)\n",
    "    macro_data8.set_index('Date', inplace=True)\n",
    "\n",
    "    macro_data9['Date'] = pd.to_datetime(macro_data9['Date'])\n",
    "    macro_data9.set_index('Date', inplace=True)\n",
    "\n",
    "    merge_data1 = dataset.join(macro_data1, how='left').fillna(method='ffill')\n",
    "    merge_data2 = merge_data1.join(macro_data2, how='left').fillna(method='ffill')\n",
    "    merge_data3 = merge_data2.join(macro_data3, how='left').fillna(method='ffill')\n",
    "    merge_data4 = merge_data3.join(macro_data4, how='left').fillna(method='ffill')\n",
    "    merge_data5 = merge_data4.join(macro_data5, how='left').fillna(method='ffill')\n",
    "    merge_data7 = merge_data5.join(macro_data7, how='left').fillna(method='ffill')\n",
    "    merge_data8 = merge_data7.join(macro_data8, how='left').fillna(method='ffill')\n",
    "    merge_final = merge_data8.join(macro_data9, how='left').fillna(method='ffill')\n",
    "\n",
    "    merge_final['RSI (14D)'] = ta.rsi(merge_final['Close'], length=14)\n",
    "    merge_final['20 Day CCI'] = ta.cci(high=merge_final['High'], low=merge_final['Low'], \n",
    "                                    close=merge_final['Close'], length=20)\n",
    "    merge_final['Williams %R'] = ta.willr(high=merge_final['High'], low=merge_final['Low'], \n",
    "                                        close=merge_final['Close'], length=14)\n",
    "    merge_final['EMA (5D)'] = merge_final['Close'].ewm(span=5, adjust=False).mean()\n",
    "    merge_final['MA50'] = merge_final['Close'].rolling(window=50).mean()\n",
    "\n",
    "    final_dataset = merge_final.dropna()\n",
    "\n",
    "    time_shifted = final_dataset.resample('M').asfreq().dropna()\n",
    "    \n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CPI', \n",
    "                'Mortgage_rate', 'Unemp_rate', 'disposable_income','GVZ', 'OVX', 'VVIX', \n",
    "                'RSI (14D)', '20 Day CCI', 'Williams %R', 'EMA (5D)', 'MA50', 'DFF']\n",
    "    \n",
    "    time_shifted[features] = time_shifted[features].astype(float)\n",
    "    time_shifted[features] = scaler.fit_transform(time_shifted[features])\n",
    "\n",
    "    return time_shifted, scaler\n",
    "\n",
    "# get dataset\n",
    "file_path = filedialog.askopenfilename(parent=root, title=\"Select A File\")\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1 loss: 0.7094\n",
      "Epoch 26 loss: 0.6899\n",
      "Epoch 51 loss: 0.6762\n",
      "Epoch 76 loss: 0.7201\n",
      "Epoch 101 loss: 0.6538\n",
      "Epoch 126 loss: 0.6859\n",
      "\n",
      "Accuracy: 0.2000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 2\n",
      "Epoch 1 loss: 0.7221\n",
      "Epoch 26 loss: 0.6927\n",
      "Epoch 51 loss: 0.6909\n",
      "Epoch 76 loss: 0.6834\n",
      "Epoch 101 loss: 0.6680\n",
      "Epoch 126 loss: 0.6217\n",
      "\n",
      "Accuracy: 0.3000\n",
      "Precision: 0.3000\n",
      "Recall: 1.0000\n",
      "F1: 0.4615\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 3\n",
      "Epoch 1 loss: 0.6886\n",
      "Epoch 26 loss: 0.6309\n",
      "Epoch 51 loss: 0.6827\n",
      "Epoch 76 loss: 0.6628\n",
      "Epoch 101 loss: 0.6903\n",
      "Epoch 126 loss: 0.6956\n",
      "\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 4\n",
      "Epoch 1 loss: 0.7557\n",
      "Epoch 26 loss: 0.6827\n",
      "Epoch 51 loss: 0.6982\n",
      "Epoch 76 loss: 0.6943\n",
      "Epoch 101 loss: 0.6397\n",
      "Epoch 126 loss: 0.6805\n",
      "\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.7500\n",
      "Recall: 0.8571\n",
      "F1: 0.8000\n",
      "Kappa: 0.2105\n",
      "\n",
      "Fold 5\n",
      "Epoch 1 loss: 0.7270\n",
      "Epoch 26 loss: 0.6936\n",
      "Epoch 51 loss: 0.7031\n",
      "Epoch 76 loss: 0.6399\n",
      "Epoch 101 loss: 0.5938\n",
      "Epoch 126 loss: 0.6272\n",
      "\n",
      "Accuracy: 0.8000\n",
      "Precision: 1.0000\n",
      "Recall: 0.6667\n",
      "F1: 0.8000\n",
      "Kappa: 0.6154\n",
      "\n",
      "Fold 6\n",
      "Epoch 1 loss: 0.6797\n",
      "Epoch 26 loss: 0.6497\n",
      "Epoch 51 loss: 0.6761\n",
      "Epoch 76 loss: 0.6328\n",
      "Epoch 101 loss: 0.7423\n",
      "Epoch 126 loss: 0.5099\n",
      "\n",
      "Accuracy: 0.4000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 7\n",
      "Epoch 1 loss: 0.6647\n",
      "Epoch 26 loss: 0.7047\n",
      "Epoch 51 loss: 0.6248\n",
      "Epoch 76 loss: 0.7286\n",
      "Epoch 101 loss: 0.7216\n",
      "Epoch 126 loss: 0.7309\n",
      "\n",
      "Accuracy: 0.6000\n",
      "Precision: 0.8000\n",
      "Recall: 0.5714\n",
      "F1: 0.6667\n",
      "Kappa: 0.2000\n",
      "\n",
      "Fold 8\n",
      "Epoch 1 loss: 0.6931\n",
      "Epoch 26 loss: 0.6918\n",
      "Epoch 51 loss: 0.6338\n",
      "Epoch 76 loss: 0.5496\n",
      "Epoch 101 loss: 0.6701\n",
      "Epoch 126 loss: 0.4445\n",
      "\n",
      "Accuracy: 0.6000\n",
      "Precision: 0.6000\n",
      "Recall: 1.0000\n",
      "F1: 0.7500\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 9\n",
      "Epoch 1 loss: 0.7320\n",
      "Epoch 26 loss: 0.6502\n",
      "Epoch 51 loss: 0.6715\n",
      "Epoch 76 loss: 0.6465\n",
      "Epoch 101 loss: 0.6521\n",
      "Epoch 126 loss: 0.5636\n",
      "\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.7000\n",
      "Recall: 1.0000\n",
      "F1: 0.8235\n",
      "Kappa: 0.0000\n",
      "\n",
      "Fold 10\n",
      "Epoch 1 loss: 0.6919\n",
      "Epoch 26 loss: 0.6226\n",
      "Epoch 51 loss: 0.4892\n",
      "Epoch 76 loss: 0.7548\n",
      "Epoch 101 loss: 0.7038\n",
      "Epoch 126 loss: 0.9753\n",
      "\n",
      "Accuracy: 0.7000\n",
      "Precision: 1.0000\n",
      "Recall: 0.6667\n",
      "F1: 0.8000\n",
      "Kappa: 0.2857\n",
      "\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.5500\n",
      "Average Precision: 0.5150\n",
      "Average Recall: 0.5762\n",
      "Average F1: 0.5102\n",
      "Average Kappa: 0.1312\n"
     ]
    }
   ],
   "source": [
    "# create LSTM model class\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer, num_layers=4, dropout=0.3):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers with dropout\n",
    "        self.lstm = nn.LSTM(input_layer, hidden_layer, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Linear layer\n",
    "        self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, input_tensor.size(0), self.hidden_layer).to(input_tensor.device)\n",
    "        c0 = torch.zeros(self.num_layers, input_tensor.size(0), self.hidden_layer).to(input_tensor.device)\n",
    "        \n",
    "        # Pass through LSTM layers\n",
    "        out, _ = self.lstm(input_tensor, (h0, c0))\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Pass through linear layer\n",
    "        out = self.linear_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(0, len(input_data) - sequence_length):\n",
    "        sequence = input_data[i : i + sequence_length, :-1]\n",
    "        label = input_data[i + sequence_length, -1]\n",
    "        sequences.append((sequence, label))\n",
    "    return sequences\n",
    "\n",
    "# train the model with data provided\n",
    "def trainer(model, train_data, loss_func, opt, epochs, fold, losses):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for sequence, labels in train_data:\n",
    "            opt.zero_grad()\n",
    "            sequence = sequence.clone().detach().float()\n",
    "            labels = labels.clone().detach().float().view(-1, 1)\n",
    "            \n",
    "            y = model(sequence)\n",
    "            loss = loss_func(y, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if epoch % 25 == 1:\n",
    "            print(f'Epoch {epoch} loss: {loss.item():.4f}')\n",
    "\n",
    "            new_row = pd.DataFrame({'Fold': [fold+1], 'Epoch': [epoch], 'Loss': [loss.item()]})\n",
    "            losses = pd.concat([losses, new_row], ignore_index=True)\n",
    "            \n",
    "    return losses\n",
    "\n",
    "def predictor(model, test_data):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for sequence, _ in test_data:\n",
    "            sequence = sequence.clone().detach().float()\n",
    "            y = model(sequence)\n",
    "            batch_predictions = torch.sigmoid(y)\n",
    "\n",
    "            # Convert predictions to tensor if they are scalar or float\n",
    "            if isinstance(batch_predictions, float) or batch_predictions.ndimension() == 0:\n",
    "                batch_predictions = torch.tensor([batch_predictions])\n",
    "\n",
    "            batch_predictions = torch.round(batch_predictions)\n",
    "\n",
    "            predictions.extend(batch_predictions.squeeze().tolist())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# create sequences\n",
    "sequence_length = 10\n",
    "sequences = create_sequence(ticker[['Close', 'Volume', 'CPI', 'Mortgage_rate', 'disposable_income',\n",
    "                                    'GVZ', 'OVX', 'VVIX', 'RSI (14D)', '20 Day CCI', 'Williams %R', \n",
    "                                    'MA50', 'Target']].values, sequence_length)\n",
    "\n",
    "# cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "kappas = []\n",
    "losses = pd.DataFrame(columns=['Fold', 'Epoch', 'Loss'])\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(sequences)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    \n",
    "    train_sequences = [sequences[i] for i in train_index]\n",
    "    test_sequences = [sequences[i] for i in test_index]\n",
    "    \n",
    "    train_data = torch.utils.data.DataLoader(train_sequences, shuffle=True, batch_size=32)\n",
    "    test_data = torch.utils.data.DataLoader(test_sequences, shuffle=False, batch_size=32)\n",
    "    \n",
    "    # initialize model\n",
    "    model = LSTM_Model(input_layer=12, hidden_layer=10, output_layer=1)\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    # train model\n",
    "    epochs = 150\n",
    "    losses = trainer(model, train_data, loss_func, opt, epochs, fold, losses)\n",
    "    \n",
    "    # make predictions\n",
    "    test_labels = [label for _, label in test_sequences]\n",
    "    predictions = predictor(model, test_data)\n",
    "    \n",
    "    # calculate statistics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    kappa = cohen_kappa_score(test_labels, predictions)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    kappas.append(kappa)\n",
    "    \n",
    "    print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1: {f1:.4f}')\n",
    "    print(f'Kappa: {kappa:.4f}\\n')\n",
    "\n",
    "# average scores across all folds\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_f1 = np.mean(f1s)\n",
    "avg_kappa = np.mean(kappas)\n",
    "\n",
    "print(f'\\nCross-Validation Results:')\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1: {avg_f1:.4f}')\n",
    "print(f'Average Kappa: {avg_kappa:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days rising: 75\n",
      "Number of days falling: 50\n",
      "Rise % is: 60.00%\n",
      "Fall % is: 40.00%\n"
     ]
    }
   ],
   "source": [
    "fall = (ticker.Target == 0).sum()\n",
    "rise = (ticker.Target == 1).sum()\n",
    "\n",
    "rise_per = (rise / (rise + fall)) * 100\n",
    "fall_per = (fall / (rise + fall)) * 100\n",
    "\n",
    "print(f'Number of days rising: {rise}')\n",
    "print(f'Number of days falling: {fall}')\n",
    "\n",
    "print(f'Rise % is: {rise_per:.2f}%')\n",
    "print(f'Fall % is: {fall_per:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1</th>\n",
       "      <th>Average Kappa</th>\n",
       "      <th>Number of Rises</th>\n",
       "      <th>Number of Falls</th>\n",
       "      <th>Rise %</th>\n",
       "      <th>Fall %</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>^SPX_Monthly</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.452908</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.666313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.659155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0.678531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0.711847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.686141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>76</td>\n",
       "      <td>0.626328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>0.723389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "      <td>0.478093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average Accuracy  Average Precision  Average Recall  Average F1  \\\n",
       "Dataset                                                                         \n",
       "^SPX_Monthly              0.48               0.42            0.59    0.452908   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "...                        ...                ...             ...         ...   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "NaN                        NaN                NaN             NaN         NaN   \n",
       "\n",
       "              Average Kappa Number of Rises Number of Falls  Rise %  Fall %  \\\n",
       "Dataset                                                                       \n",
       "^SPX_Monthly       0.008571              75              50    60.0    40.0   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "...                     ...             ...             ...     ...     ...   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "NaN                     NaN             NaN             NaN     NaN     NaN   \n",
       "\n",
       "             Fold Epoch      Loss  \n",
       "Dataset                            \n",
       "^SPX_Monthly  NaN   NaN       NaN  \n",
       "NaN             1     1  0.706665  \n",
       "NaN             1    26  0.666313  \n",
       "NaN             1    51  0.659155  \n",
       "NaN             1    76  0.678531  \n",
       "...           ...   ...       ...  \n",
       "NaN            10    26  0.711847  \n",
       "NaN            10    51  0.686141  \n",
       "NaN            10    76  0.626328  \n",
       "NaN            10   101  0.723389  \n",
       "NaN            10   126  0.478093  \n",
       "\n",
       "[61 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Dataset', 'Average Accuracy', 'Average Precision', \n",
    "                                'Average Recall', 'Average F1', 'Average Kappa', 'Number of Rises', \n",
    "                                'Number of Falls', 'Rise %', 'Fall %'])\n",
    "\n",
    "datatset_name = (file_path.split('/')[-1].split('.')[0] + '_Monthly')\n",
    "\n",
    "metrics = {'Dataset': datatset_name ,'Average Accuracy': avg_accuracy, \n",
    "           'Average Precision': avg_precision, 'Average Recall': avg_recall, \n",
    "           'Average F1': avg_f1, 'Average Kappa': avg_kappa, 'Number of Rises': rise, 'Number of Falls': fall, \n",
    "           'Rise %': rise_per, 'Fall %': fall_per}\n",
    "\n",
    "export_results = results._append(metrics, ignore_index=True)\n",
    "\n",
    "export_results = pd.concat([export_results, losses], ignore_index=True)\n",
    "\n",
    "export_results.set_index('Dataset', inplace=True)\n",
    "\n",
    "export_results.to_csv(r\"C:\\Users\\samto\\Desktop\\IRP DATA-20240724T195545Z-001\\IRP DATA\\\\\" + datatset_name + '_monthly_w_macro.csv')\n",
    "\n",
    "export_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
