{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0      Open      High       Low     Close     Adj Close  \\\n",
      "49   1991-07-01 -0.793459 -0.794274 -0.792834 -0.793512    481.309998   \n",
      "50   1991-08-01 -0.785622 -0.786959 -0.784756 -0.786118    504.149994   \n",
      "51   1991-10-01 -0.777571 -0.779061 -0.776878 -0.778232    528.510010   \n",
      "52   1991-11-01 -0.772706 -0.774313 -0.772308 -0.774211    540.929993   \n",
      "53   1992-04-01 -0.754432 -0.755420 -0.753462 -0.754411    602.090027   \n",
      "..          ...       ...       ...       ...       ...           ...   \n",
      "279  2021-07-01  3.743657  3.726129  3.762053  3.752103  14522.379880   \n",
      "280  2021-09-01  4.007581  3.998264  4.043490  4.006884  15309.379880   \n",
      "281  2021-10-01  3.744058  3.749699  3.724410  3.766452  14566.700200   \n",
      "282  2021-11-01  4.082774  4.068859  4.098527  4.099648  15595.919920   \n",
      "283  2021-12-01  4.151082  4.138946  4.024510  3.988972  15254.049810   \n",
      "\n",
      "       Volume      CPI  Mortgage_rate  Unemp_rate  disposable_income  \\\n",
      "49  -1.135636  136.200       1.192941    0.476384          -1.159748   \n",
      "50  -1.103749  136.600       1.059833    0.534575          -1.154240   \n",
      "51  -1.101594  137.200       0.903402    0.592766          -1.144141   \n",
      "52  -1.065890  137.800       0.845896    0.592766          -1.140367   \n",
      "53  -1.086983  139.400       0.902396    0.825528          -1.074197   \n",
      "..        ...      ...            ...         ...                ...   \n",
      "279  2.446944  272.184      -1.504201   -0.338284           1.852898   \n",
      "280  2.331010  274.214      -1.491332   -0.745619           1.761464   \n",
      "281  2.697769  276.590      -1.423974   -0.803809           1.763539   \n",
      "282  3.168282  278.524      -1.423974   -1.036572           1.762995   \n",
      "283  4.042353  280.126      -1.411709   -1.211143           1.753440   \n",
      "\n",
      "     Personal_consumption_expenditure  personal_savings  RSI (14D)  \\\n",
      "49                          -1.111277          0.346438  -0.393576   \n",
      "50                          -1.110459          0.472577  -0.191907   \n",
      "51                          -1.108638          0.693320   0.010196   \n",
      "52                          -1.101353          0.598716   0.109872   \n",
      "53                          -1.067593          0.882529   0.537577   \n",
      "..                                ...               ...        ...   \n",
      "279                          2.016264          1.071737   1.419937   \n",
      "280                          2.088586          0.314903   1.559019   \n",
      "281                          2.146814          0.125695   0.942353   \n",
      "282                          2.168300          0.157230   1.168795   \n",
      "283                          2.129077          0.504112   0.909048   \n",
      "\n",
      "     20 Day CCI  Williams %R      EMA (5D)      MA10      MA50  Target  \n",
      "49     0.125310     0.638341    463.315369 -0.809164 -0.823858       1  \n",
      "50     0.497262     0.775676    476.926911 -0.806501 -0.822199       1  \n",
      "51     0.829999     0.772793    494.121277 -0.804351 -0.820580       1  \n",
      "52     0.866166     0.736029    509.724182 -0.800951 -0.818937       1  \n",
      "53     1.474526     0.775468    540.512797 -0.792942 -0.816853       0  \n",
      "..          ...          ...           ...       ...       ...     ...  \n",
      "279    0.430587     0.773295  13577.078971  3.066925  1.513104       1  \n",
      "280    0.470339     0.748838  14154.512607  3.253312  1.579819       0  \n",
      "281    0.102715     0.433729  14291.908471  3.396147  1.641224       1  \n",
      "282    0.277095     0.777112  14726.578954  3.514513  1.709745       0  \n",
      "283    0.135297     0.475069  14902.402573  3.641662  1.778494       0  \n",
      "\n",
      "[235 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_11800\\1195822878.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float()\n",
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_11800\\1195822878.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).float().view(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.9443248510360718\n",
      "Epoch 26 loss: 0.35145068168640137\n",
      "Epoch 51 loss: 0.08487936109304428\n",
      "Epoch 76 loss: 0.2745114862918854\n",
      "Epoch 101 loss: 0.8494176864624023\n",
      "Epoch 126 loss: 0.044519905000925064\n",
      "Confusion Matrix:\n",
      "[[ 6  7]\n",
      " [18 14]]\n",
      "Accuracy: 0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_11800\\1195822878.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize the Tkinter root window\n",
    "root = tk.Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "\n",
    "# Normalize data and assign movement direction values\n",
    "def prep(dataset):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    dataset['RSI (14D)'] = ta.rsi(dataset['Close'], length=14)\n",
    "    dataset['20 Day CCI'] = ta.cci(high=dataset['High'], low=dataset['Low'], \n",
    "                                   close=dataset['Close'], length=20)\n",
    "    dataset['Williams %R'] = ta.willr(high=dataset['High'], low=dataset['Low'], \n",
    "                                      close=dataset['Close'], length=14)\n",
    "    dataset['EMA (5D)'] = dataset['Close'].ewm(span=5, adjust=False).mean()\n",
    "\n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI (14D)', \n",
    "                '20 Day CCI', 'Williams %R', 'Mortgage_rate', 'Unemp_rate',\n",
    "                'disposable_income', 'Personal_consumption_expenditure', \n",
    "                'personal_savings']\n",
    "    \n",
    "    dataset[features] = dataset[features].astype(float)\n",
    "    dataset[features] = scaler.fit_transform(dataset[features])\n",
    "\n",
    "    dataset['MA10'] = dataset['Close'].rolling(window=10).mean()\n",
    "    dataset['MA50'] = dataset['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "    prepared_data = dataset.dropna()\n",
    "\n",
    "    return prepared_data, scaler\n",
    "\n",
    "# Define LSTM Model class\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.lstm1 = nn.LSTM(input_layer, hidden_layer, batch_first=True, bidirectional=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lstm2 = nn.LSTM(hidden_layer, hidden_layer, batch_first=True, bidirectional=False)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "        self.hidden_cell1 = (torch.zeros(1,1,self.hidden_layer),\n",
    "                            torch.zeros(1,1,self.hidden_layer))\n",
    "        self.hidden_cell2 = (torch.zeros(1,1,self.hidden_layer),\n",
    "                            torch.zeros(1,1,self.hidden_layer))\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        self.hidden_cell1 = (torch.zeros(1, input_tensor.size(0), self.hidden_layer), \n",
    "                            torch.zeros(1, input_tensor.size(0), self.hidden_layer))\n",
    "        self.hidden_cell2 = (torch.zeros(1, input_tensor.size(0), self.hidden_layer), \n",
    "                            torch.zeros(1, input_tensor.size(0), self.hidden_layer))\n",
    "        \n",
    "        out, self.hidden_cell1 = self.lstm1(input_tensor, self.hidden_cell1)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out, self.hidden_cell2 = self.lstm2(out, self.hidden_cell2)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        lstm_out_last = out[:, -1, :]\n",
    "\n",
    "        output = self.linear_layer(lstm_out_last)\n",
    "\n",
    "        return output\n",
    "\n",
    "# create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "  sequences = []\n",
    "  for i in range(len(input_data) - sequence_length):\n",
    "    sequence = input_data[i : i + sequence_length, :-1]\n",
    "    label = input_data[i + sequence_length, -1]\n",
    "    sequences.append((sequence, label))\n",
    "  return sequences\n",
    "\n",
    "# train the model with data provided\n",
    "def trainer(model, train_data, loss_func, opt, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    for sequence, labels, in train_data:\n",
    "      opt.zero_grad()\n",
    "      model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer),\n",
    "                           torch.zeros(1, 1, model.hidden_layer))\n",
    "      \n",
    "      sequence = torch.tensor(sequence).float()\n",
    "      labels = torch.tensor(labels).float().view(-1, 1)\n",
    "\n",
    "      # Initialize the hidden state at the start of each sequence\n",
    "      model.hidden_cell = (torch.zeros(1, sequence.size(0), \n",
    "                                       model.hidden_layer),\n",
    "                            torch.zeros(1, sequence.size(0), \n",
    "                                        model.hidden_layer))\n",
    "\n",
    "      y = model(sequence)\n",
    "      loss = loss_func(y, labels)\n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "\n",
    "    # print progress as the model runs\n",
    "    if epoch % 25 == 1:\n",
    "      print(f'Epoch {epoch} loss: {loss.item()}')\n",
    "\n",
    "# make predictions using trained model\n",
    "def predictor(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for sequence, _ in test_data:\n",
    "            sequence = torch.tensor(sequence).float()\n",
    "\n",
    "            # Initialize the hidden state at the start of each sequence\n",
    "            model.hidden_cell = (torch.zeros(1, sequence.size(0), \n",
    "                                             model.hidden_layer),\n",
    "                                 torch.zeros(1, sequence.size(0), \n",
    "                                             model.hidden_layer))\n",
    "            \n",
    "            y = model(sequence)\n",
    "            predictions.append(torch.round(torch.sigmoid(y)).item())\n",
    "    return predictions\n",
    "\n",
    "# Load and prepare data\n",
    "file_path = filedialog.askopenfilename(parent=root, title=\"Select A File\")\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "# Create sequences\n",
    "sequence_length = 10\n",
    "sequences = create_sequence(ticker[['Open', 'High', 'Low', 'Close', 'Volume', \n",
    "                                    'RSI (14D)', '20 Day CCI', 'Williams %R', 'Mortgage_rate', \n",
    "                                    'Unemp_rate','disposable_income', 'Personal_consumption_expenditure', \n",
    "                                    'personal_savings', 'MA10', 'MA50', 'Target']].values, sequence_length)\n",
    "\n",
    "# split test/train and create dataloader\n",
    "train_size = int(len(sequences) * 0.8) # set train size\n",
    "train_sequences = sequences[ : train_size]\n",
    "test_sequences = sequences[train_size : ]\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_sequences, shuffle=True, batch_size=1)\n",
    "test_data = torch.utils.data.DataLoader(test_sequences, shuffle=True, batch_size=1)\n",
    "\n",
    "# Initialize model\n",
    "model = LSTM_Model(input_layer=15, hidden_layer=50, output_layer=1)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001) # weight_decay=0.01\n",
    "\n",
    "# Train\n",
    "epochs = 150\n",
    "trainer(model, train_data, loss_func, opt, epochs)\n",
    "\n",
    "# run model and predict values\n",
    "test_labels = [label for _, label in test_sequences]\n",
    "predictions = predictor(model, test_data)\n",
    "\n",
    "# calcluate statistics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "print(f'Confusion Matrix:\\n{cm}')\n",
    "print(f'Accuracy: {accuracy}') \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
