{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.5599114894866943\n",
      "Epoch 26 loss: 0.5266392230987549\n",
      "Epoch 51 loss: 0.1687854528427124\n",
      "Epoch 76 loss: 0.24095119535923004\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas_ta as ta\n",
    "\n",
    "# this is a change\n",
    "root = tk.Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "\n",
    "# model, data prep, and model run\n",
    "\n",
    "# normalize data and assign movement direction values\n",
    "def prep(dataset):\n",
    "  scaler = StandardScaler()\n",
    "\n",
    "  dataset['RSI (14D)'] = ta.rsi(dataset['Close'], length=14)\n",
    "  dataset['20 Day CCI'] = ta.cci(high=dataset['High'], low=dataset['Low'], \n",
    "                                 close=dataset['Close'], length=20)\n",
    "  dataset['Williams %R'] = ta.willr(high=dataset['High'], low=dataset['Low'], \n",
    "                                    close=dataset['Close'], length=14)\n",
    "  dataset['EMA (5D)'] = dataset['Close'].ewm(span=5, adjust=False).mean()\n",
    "\n",
    "  bollinger = ta.bbands(dataset['Close'], length=20, std=2)\n",
    "  dataset['BB_upper'] = bollinger['BBU_20_2.0']\n",
    "  dataset['BB_middle'] = bollinger['BBM_20_2.0']\n",
    "  dataset['BB_lower'] = bollinger['BBL_20_2.0']\n",
    "\n",
    "  features = ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI (14D)', \n",
    "              '20 Day CCI', 'Williams %R','BB_middle']\n",
    "  \n",
    "  dataset[features] = dataset[features].astype(float)\n",
    "  dataset[features] = scaler.fit_transform(dataset[features])\n",
    "\n",
    "  dataset['MA10'] = dataset['Close'].rolling(window=10).mean()\n",
    "  # dataset['MA50'] = dataset['Close'].rolling(window=50).mean()\n",
    "  \n",
    "  dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "  prepared_data = dataset.dropna()\n",
    "\n",
    "  #print(prepared_data)\n",
    "\n",
    "  return prepared_data, scaler\n",
    "\n",
    "# create LSTM model class\n",
    "class LSTM_Model(nn.Module):\n",
    "  def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "    super(LSTM_Model, self).__init__()\n",
    "    self.hidden_layer = hidden_layer\n",
    "    self.lstm = nn.LSTM(input_layer, hidden_layer, batch_first=True)\n",
    "    self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "    self.hidden_cell = (torch.zeros(1,1,self.hidden_layer).cuda(),\n",
    "                        torch.zeros(1,1,self.hidden_layer).cuda())\n",
    "\n",
    "  # Define the forward pass of the LSTM_Model\n",
    "  def forward(self, input_tensor):\n",
    "\n",
    "    self.hidden_cell = (torch.zeros(1, input_tensor.size(0), self.hidden_layer).cuda(), \n",
    "                        torch.zeros(1, input_tensor.size(0), self.hidden_layer).cuda())\n",
    "    \n",
    "    out, self.hidden_cell = self.lstm(input_tensor, self.hidden_cell)\n",
    "    lstm_out_last = out[:, -1, :]\n",
    "    predicted_values = self.linear_layer(lstm_out_last)\n",
    "    return predicted_values\n",
    "\n",
    "# create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "  sequences = []\n",
    "  for i in range(len(input_data) - sequence_length):\n",
    "    sequence = input_data[i : i + sequence_length, :-1]\n",
    "    label = input_data[i + sequence_length, -1]\n",
    "    sequences.append((sequence, label))\n",
    "  return sequences\n",
    "\n",
    "# train the model with data provided\n",
    "def trainer(model, train_data, loss_func, opt, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    for sequence, labels, in train_data:\n",
    "      opt.zero_grad()\n",
    "      model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer),\n",
    "                           torch.zeros(1, 1, model.hidden_layer))\n",
    "      \n",
    "      sequence = sequence.clone().detach().float().cuda()\n",
    "      labels = labels.clone().detach().float().view(-1, 1).cuda()\n",
    "\n",
    "      # Initialize the hidden state at the start of each sequence\n",
    "      model.hidden_cell = (torch.zeros(1, sequence.size(0), \n",
    "                                       model.hidden_layer),\n",
    "                            torch.zeros(1, sequence.size(0), \n",
    "                                        model.hidden_layer))\n",
    "\n",
    "      y = model(sequence)\n",
    "      loss = loss_func(y, labels)\n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "\n",
    "    # print progress as the model runs\n",
    "    if epoch % 25 == 1:\n",
    "      print(f'Epoch {epoch} loss: {loss.item()}')\n",
    "\n",
    "# make predictions using trained model\n",
    "def predictor(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for sequence, _ in test_data:\n",
    "            sequence = torch.tensor(sequence).float().cuda()\n",
    "\n",
    "            # Initialize the hidden state at the start of each sequence\n",
    "            model.hidden_cell = (torch.zeros(1, sequence.size(0), \n",
    "                                             model.hidden_layer),\n",
    "                                 torch.zeros(1, sequence.size(0), \n",
    "                                             model.hidden_layer))\n",
    "            \n",
    "            y = model(sequence)\n",
    "            predictions.append(torch.round(torch.sigmoid(y)).item())\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# load and prep data\n",
    "\n",
    "# get dataset\n",
    "file_path = filedialog.askopenfilename(parent=root,  title=\"Select A File\")\n",
    "\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "# create sequences\n",
    "sequence_length = 10\n",
    "sequences = create_sequence(ticker[['Open', 'High', 'Low', 'Close', 'Volume', 'RSI (14D)', '20 Day CCI', \n",
    "                                    'Williams %R','BB_middle', 'Target']].values, sequence_length)\n",
    "\n",
    "# split test/train and create dataloader\n",
    "train_size = int(len(sequences) * 0.6) # set train size\n",
    "train_sequences = sequences[ : train_size]\n",
    "test_sequences = sequences[train_size : ]\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_sequences, shuffle=True, batch_size=1)\n",
    "test_data = torch.utils.data.DataLoader(test_sequences, shuffle=True, batch_size=1)\n",
    "\n",
    "# initialise model\n",
    "model = LSTM_Model(input_layer=9, hidden_layer=150, output_layer=1)\n",
    "model.to('cuda') # move model to the GPU\n",
    "loss_func = nn.BCEWithLogitsLoss() # is this the best one?\n",
    "opt = optim.Adam(model.parameters(), lr=0.001) # and this?\n",
    "\n",
    "# train\n",
    "epochs = 150 # is this optimal?\n",
    "trainer(model, train_data, loss_func, opt, epochs)\n",
    "\n",
    "# run model and predict values\n",
    "test_labels = [label for _, label in test_sequences]\n",
    "predictions = predictor(model, test_data)\n",
    "\n",
    "# calcluate statistics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "\n",
    "print(f'Confusion Matrix:\\n{cm}')\n",
    "print(f'Accuracy: {accuracy}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.4772727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n",
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Open, Importance: -0.006198347107438051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: High, Importance: -0.0041322314049587194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Low, Importance: -0.022727272727272707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Close, Importance: -0.018595041322314043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Volume, Importance: -0.024793388429752095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: RSI (14D), Importance: 0.002066115702479332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 20 Day CCI, Importance: -0.02066115702479343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Williams %R, Importance: -0.01446280991735538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_16732\\2608877009.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float().cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: BB_middle, Importance: -0.01446280991735538\n",
      "Feature Importances (sorted):\n",
      "RSI (14D): 0.002066115702479332\n",
      "High: -0.0041322314049587194\n",
      "Open: -0.006198347107438051\n",
      "Williams %R: -0.01446280991735538\n",
      "BB_middle: -0.01446280991735538\n",
      "Close: -0.018595041322314043\n",
      "20 Day CCI: -0.02066115702479343\n",
      "Low: -0.022727272727272707\n",
      "Volume: -0.024793388429752095\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "baseline_predictions = predictor(model, test_data)\n",
    "baseline_accuracy = accuracy_score(test_labels, baseline_predictions)\n",
    "print(f'Baseline Accuracy: {baseline_accuracy}')\n",
    "\n",
    "\n",
    "def permutation_importance(model, test_data, test_labels, sequence_length, features, scaler):\n",
    "    baseline_predictions = predictor(model, test_data)\n",
    "    baseline_accuracy = accuracy_score(test_labels, baseline_predictions)\n",
    "    feature_importances = {}\n",
    "    \n",
    "    for feature_idx, feature in enumerate(features):\n",
    "        shuffled_test_data = copy.deepcopy(ticker)\n",
    "        \n",
    "        # Shuffle the specific feature column\n",
    "        shuffled_test_data[feature] = np.random.permutation(shuffled_test_data[feature].values)\n",
    "        \n",
    "        # Create sequences for shuffled data\n",
    "        shuffled_sequences = create_sequence(shuffled_test_data[features + ['Target']].values, sequence_length)\n",
    "        \n",
    "        # Split shuffled data into test sequences\n",
    "        shuffled_test_data = torch.utils.data.DataLoader(shuffled_sequences[train_size:], shuffle=False, batch_size=1)\n",
    "        \n",
    "        # Get predictions with shuffled data\n",
    "        shuffled_predictions = predictor(model, shuffled_test_data)\n",
    "        \n",
    "        # Calculate the accuracy with shuffled data\n",
    "        shuffled_accuracy = accuracy_score(test_labels, shuffled_predictions)\n",
    "        \n",
    "        # Calculate importance as the drop in accuracy\n",
    "        feature_importance = baseline_accuracy - shuffled_accuracy\n",
    "        feature_importances[feature] = feature_importance\n",
    "        print(f'Feature: {feature}, Importance: {feature_importance}')\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI (14D)', \n",
    "              '20 Day CCI', 'Williams %R','BB_middle']\n",
    "\n",
    "feature_importances = permutation_importance(model, test_data, test_labels, sequence_length, features, scaler)\n",
    "\n",
    "# Sort and print the feature importances\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Feature Importances (sorted):\")\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f'{feature}: {importance}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
