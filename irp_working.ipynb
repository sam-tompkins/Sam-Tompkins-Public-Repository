{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_15680\\852049816.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float()\n",
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_15680\\852049816.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).float().view(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.833328366279602\n",
      "Epoch 26 loss: 0.6814336180686951\n",
      "Confusion Matrix:\n",
      "[[47 59]\n",
      " [75 69]]\n",
      "Accuracy: 0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samto\\AppData\\Local\\Temp\\ipykernel_15680\\852049816.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence = torch.tensor(sequence).float()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "# model, data prep, and model run\n",
    "\n",
    "# normalize data and assign movement direction values\n",
    "def prep(dataset):\n",
    "  scaler = StandardScaler()\n",
    "  features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "  dataset[features] = dataset[features].astype(float)\n",
    "  dataset[features] = scaler.fit_transform(dataset[features])\n",
    "\n",
    "  dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "  prepared_data = dataset.dropna()\n",
    "  return prepared_data, scaler\n",
    "\n",
    "# create LSTM model class\n",
    "class LSTM_Model(nn.Module):\n",
    "  def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "    super(LSTM_Model, self).__init__()\n",
    "    self.hidden_layer = hidden_layer\n",
    "    self.lstm = nn.LSTM(input_layer, hidden_layer, batch_first=True)\n",
    "    self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "    self.hidden_cell = (torch.zeros(1,1,self.hidden_layer),\n",
    "                        torch.zeros(1,1,self.hidden_layer))\n",
    "\n",
    "  # Define the forward pass of the LSTM_Model\n",
    "  def forward(self, input_tensor):\n",
    "\n",
    "    self.hidden_cell = (torch.zeros(1, input_tensor.size(0), self.hidden_layer), \n",
    "                        torch.zeros(1, input_tensor.size(0), self.hidden_layer))\n",
    "    \n",
    "    out, self.hidden_cell = self.lstm(input_tensor, self.hidden_cell)\n",
    "    lstm_out_last = out[:, -1, :]\n",
    "    predicted_values = self.linear_layer(lstm_out_last)\n",
    "    return predicted_values\n",
    "\n",
    "# create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "  sequences = []\n",
    "  for i in range(len(input_data) - sequence_length):\n",
    "    sequence = input_data[i : i + sequence_length, :-1]\n",
    "    label = input_data[i + sequence_length, -1]\n",
    "    sequences.append((sequence, label))\n",
    "  return sequences\n",
    "\n",
    "# train the model with data provided\n",
    "def trainer(model, train_data, loss_func, opt, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    for sequence, labels, in train_data:\n",
    "      opt.zero_grad()\n",
    "      model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer),\n",
    "                           torch.zeros(1, 1, model.hidden_layer))\n",
    "      \n",
    "      sequence = torch.tensor(sequence).float()\n",
    "      labels = torch.tensor(labels).float().view(-1, 1)\n",
    "\n",
    "      # Initialize the hidden state at the start of each sequence\n",
    "      model.hidden_cell = (torch.zeros(1, sequence.size(0), \n",
    "                                       model.hidden_layer),\n",
    "                            torch.zeros(1, sequence.size(0), \n",
    "                                        model.hidden_layer))\n",
    "\n",
    "      y = model(sequence)\n",
    "      loss = loss_func(y, labels)\n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "\n",
    "    # print progress as the model runs\n",
    "    if epoch % 25 == 1:\n",
    "      print(f'Epoch {epoch} loss: {loss.item()}')\n",
    "\n",
    "# make predictions using trained model\n",
    "def predictor(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for sequence, _ in test_data:\n",
    "            sequence = torch.tensor(sequence).float()\n",
    "\n",
    "            # Initialize the hidden state at the start of each sequence\n",
    "            model.hidden_cell = (torch.zeros(1, sequence.size(0), \n",
    "                                             model.hidden_layer),\n",
    "                                 torch.zeros(1, sequence.size(0), \n",
    "                                             model.hidden_layer))\n",
    "            \n",
    "            y = model(sequence)\n",
    "            predictions.append(torch.round(torch.sigmoid(y)).item())\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# load and prep data\n",
    "\n",
    "# get dataset\n",
    "file_path = filedialog.askopenfilename()\n",
    "\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "# create sequences\n",
    "sequence_length = 10\n",
    "sequences = create_sequence(ticker[['Open', 'High', 'Low', 'Close', 'Volume', \n",
    "                                    'Target']].values, sequence_length)\n",
    "\n",
    "# split test/train and create dataloader\n",
    "train_size = int(len(sequences) * 0.8) # set train size\n",
    "train_sequences = sequences[ : train_size]\n",
    "test_sequences = sequences[train_size : ]\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_sequences, shuffle=True, batch_size=1)\n",
    "test_data = torch.utils.data.DataLoader(test_sequences, shuffle=True, batch_size=1)\n",
    "\n",
    "# initialise model\n",
    "model = LSTM_Model(input_layer=5, hidden_layer=50, output_layer=1)\n",
    "loss_func = nn.BCEWithLogitsLoss() # is this the best one?\n",
    "opt = optim.Adam(model.parameters(), lr=0.001) # and this?\n",
    "\n",
    "# train\n",
    "epochs = 150 # is this optimal?\n",
    "trainer(model, train_data, loss_func, opt, epochs)\n",
    "\n",
    "# run model and predict values\n",
    "test_labels = [label for _, label in test_sequences]\n",
    "predictions = predictor(model, test_data)\n",
    "\n",
    "# calcluate statistics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "\n",
    "print(f'Confusion Matrix:\\n{cm}')\n",
    "print(f'Accuracy: {accuracy}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47, 59],\n",
       "       [75, 69]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
