{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Mortgage_rate</th>\n",
       "      <th>Unemp_rate</th>\n",
       "      <th>disposable_income</th>\n",
       "      <th>Personal_consumption_expenditure</th>\n",
       "      <th>personal_savings</th>\n",
       "      <th>RSI (14D)</th>\n",
       "      <th>20 Day CCI</th>\n",
       "      <th>Williams %R</th>\n",
       "      <th>EMA (5D)</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA50</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1991-07-01</td>\n",
       "      <td>-0.793459</td>\n",
       "      <td>-0.794274</td>\n",
       "      <td>-0.792834</td>\n",
       "      <td>-0.793512</td>\n",
       "      <td>481.309998</td>\n",
       "      <td>-1.135636</td>\n",
       "      <td>136.200</td>\n",
       "      <td>1.192941</td>\n",
       "      <td>0.476384</td>\n",
       "      <td>-1.159748</td>\n",
       "      <td>-1.111277</td>\n",
       "      <td>0.346438</td>\n",
       "      <td>-0.393576</td>\n",
       "      <td>0.125310</td>\n",
       "      <td>0.638341</td>\n",
       "      <td>463.315369</td>\n",
       "      <td>-0.809164</td>\n",
       "      <td>-0.823858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1991-08-01</td>\n",
       "      <td>-0.785622</td>\n",
       "      <td>-0.786959</td>\n",
       "      <td>-0.784756</td>\n",
       "      <td>-0.786118</td>\n",
       "      <td>504.149994</td>\n",
       "      <td>-1.103749</td>\n",
       "      <td>136.600</td>\n",
       "      <td>1.059833</td>\n",
       "      <td>0.534575</td>\n",
       "      <td>-1.154240</td>\n",
       "      <td>-1.110459</td>\n",
       "      <td>0.472577</td>\n",
       "      <td>-0.191907</td>\n",
       "      <td>0.497262</td>\n",
       "      <td>0.775676</td>\n",
       "      <td>476.926911</td>\n",
       "      <td>-0.806501</td>\n",
       "      <td>-0.822199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1991-10-01</td>\n",
       "      <td>-0.777571</td>\n",
       "      <td>-0.779061</td>\n",
       "      <td>-0.776878</td>\n",
       "      <td>-0.778232</td>\n",
       "      <td>528.510010</td>\n",
       "      <td>-1.101594</td>\n",
       "      <td>137.200</td>\n",
       "      <td>0.903402</td>\n",
       "      <td>0.592766</td>\n",
       "      <td>-1.144141</td>\n",
       "      <td>-1.108638</td>\n",
       "      <td>0.693320</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.829999</td>\n",
       "      <td>0.772793</td>\n",
       "      <td>494.121277</td>\n",
       "      <td>-0.804351</td>\n",
       "      <td>-0.820580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1991-11-01</td>\n",
       "      <td>-0.772706</td>\n",
       "      <td>-0.774313</td>\n",
       "      <td>-0.772308</td>\n",
       "      <td>-0.774211</td>\n",
       "      <td>540.929993</td>\n",
       "      <td>-1.065890</td>\n",
       "      <td>137.800</td>\n",
       "      <td>0.845896</td>\n",
       "      <td>0.592766</td>\n",
       "      <td>-1.140367</td>\n",
       "      <td>-1.101353</td>\n",
       "      <td>0.598716</td>\n",
       "      <td>0.109872</td>\n",
       "      <td>0.866166</td>\n",
       "      <td>0.736029</td>\n",
       "      <td>509.724182</td>\n",
       "      <td>-0.800951</td>\n",
       "      <td>-0.818937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1992-04-01</td>\n",
       "      <td>-0.754432</td>\n",
       "      <td>-0.755420</td>\n",
       "      <td>-0.753462</td>\n",
       "      <td>-0.754411</td>\n",
       "      <td>602.090027</td>\n",
       "      <td>-1.086983</td>\n",
       "      <td>139.400</td>\n",
       "      <td>0.902396</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>-1.074197</td>\n",
       "      <td>-1.067593</td>\n",
       "      <td>0.882529</td>\n",
       "      <td>0.537577</td>\n",
       "      <td>1.474526</td>\n",
       "      <td>0.775468</td>\n",
       "      <td>540.512797</td>\n",
       "      <td>-0.792942</td>\n",
       "      <td>-0.816853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>3.743657</td>\n",
       "      <td>3.726129</td>\n",
       "      <td>3.762053</td>\n",
       "      <td>3.752103</td>\n",
       "      <td>14522.379880</td>\n",
       "      <td>2.446944</td>\n",
       "      <td>272.184</td>\n",
       "      <td>-1.504201</td>\n",
       "      <td>-0.338284</td>\n",
       "      <td>1.852898</td>\n",
       "      <td>2.016264</td>\n",
       "      <td>1.071737</td>\n",
       "      <td>1.419937</td>\n",
       "      <td>0.430587</td>\n",
       "      <td>0.773295</td>\n",
       "      <td>13577.078971</td>\n",
       "      <td>3.066925</td>\n",
       "      <td>1.513104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>4.007581</td>\n",
       "      <td>3.998264</td>\n",
       "      <td>4.043490</td>\n",
       "      <td>4.006884</td>\n",
       "      <td>15309.379880</td>\n",
       "      <td>2.331010</td>\n",
       "      <td>274.214</td>\n",
       "      <td>-1.491332</td>\n",
       "      <td>-0.745619</td>\n",
       "      <td>1.761464</td>\n",
       "      <td>2.088586</td>\n",
       "      <td>0.314903</td>\n",
       "      <td>1.559019</td>\n",
       "      <td>0.470339</td>\n",
       "      <td>0.748838</td>\n",
       "      <td>14154.512607</td>\n",
       "      <td>3.253312</td>\n",
       "      <td>1.579819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>3.744058</td>\n",
       "      <td>3.749699</td>\n",
       "      <td>3.724410</td>\n",
       "      <td>3.766452</td>\n",
       "      <td>14566.700200</td>\n",
       "      <td>2.697769</td>\n",
       "      <td>276.590</td>\n",
       "      <td>-1.423974</td>\n",
       "      <td>-0.803809</td>\n",
       "      <td>1.763539</td>\n",
       "      <td>2.146814</td>\n",
       "      <td>0.125695</td>\n",
       "      <td>0.942353</td>\n",
       "      <td>0.102715</td>\n",
       "      <td>0.433729</td>\n",
       "      <td>14291.908471</td>\n",
       "      <td>3.396147</td>\n",
       "      <td>1.641224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>4.082774</td>\n",
       "      <td>4.068859</td>\n",
       "      <td>4.098527</td>\n",
       "      <td>4.099648</td>\n",
       "      <td>15595.919920</td>\n",
       "      <td>3.168282</td>\n",
       "      <td>278.524</td>\n",
       "      <td>-1.423974</td>\n",
       "      <td>-1.036572</td>\n",
       "      <td>1.762995</td>\n",
       "      <td>2.168300</td>\n",
       "      <td>0.157230</td>\n",
       "      <td>1.168795</td>\n",
       "      <td>0.277095</td>\n",
       "      <td>0.777112</td>\n",
       "      <td>14726.578954</td>\n",
       "      <td>3.514513</td>\n",
       "      <td>1.709745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>4.151082</td>\n",
       "      <td>4.138946</td>\n",
       "      <td>4.024510</td>\n",
       "      <td>3.988972</td>\n",
       "      <td>15254.049810</td>\n",
       "      <td>4.042353</td>\n",
       "      <td>280.126</td>\n",
       "      <td>-1.411709</td>\n",
       "      <td>-1.211143</td>\n",
       "      <td>1.753440</td>\n",
       "      <td>2.129077</td>\n",
       "      <td>0.504112</td>\n",
       "      <td>0.909048</td>\n",
       "      <td>0.135297</td>\n",
       "      <td>0.475069</td>\n",
       "      <td>14902.402573</td>\n",
       "      <td>3.641662</td>\n",
       "      <td>1.778494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      Open      High       Low     Close     Adj Close  \\\n",
       "49   1991-07-01 -0.793459 -0.794274 -0.792834 -0.793512    481.309998   \n",
       "50   1991-08-01 -0.785622 -0.786959 -0.784756 -0.786118    504.149994   \n",
       "51   1991-10-01 -0.777571 -0.779061 -0.776878 -0.778232    528.510010   \n",
       "52   1991-11-01 -0.772706 -0.774313 -0.772308 -0.774211    540.929993   \n",
       "53   1992-04-01 -0.754432 -0.755420 -0.753462 -0.754411    602.090027   \n",
       "..          ...       ...       ...       ...       ...           ...   \n",
       "279  2021-07-01  3.743657  3.726129  3.762053  3.752103  14522.379880   \n",
       "280  2021-09-01  4.007581  3.998264  4.043490  4.006884  15309.379880   \n",
       "281  2021-10-01  3.744058  3.749699  3.724410  3.766452  14566.700200   \n",
       "282  2021-11-01  4.082774  4.068859  4.098527  4.099648  15595.919920   \n",
       "283  2021-12-01  4.151082  4.138946  4.024510  3.988972  15254.049810   \n",
       "\n",
       "       Volume      CPI  Mortgage_rate  Unemp_rate  disposable_income  \\\n",
       "49  -1.135636  136.200       1.192941    0.476384          -1.159748   \n",
       "50  -1.103749  136.600       1.059833    0.534575          -1.154240   \n",
       "51  -1.101594  137.200       0.903402    0.592766          -1.144141   \n",
       "52  -1.065890  137.800       0.845896    0.592766          -1.140367   \n",
       "53  -1.086983  139.400       0.902396    0.825528          -1.074197   \n",
       "..        ...      ...            ...         ...                ...   \n",
       "279  2.446944  272.184      -1.504201   -0.338284           1.852898   \n",
       "280  2.331010  274.214      -1.491332   -0.745619           1.761464   \n",
       "281  2.697769  276.590      -1.423974   -0.803809           1.763539   \n",
       "282  3.168282  278.524      -1.423974   -1.036572           1.762995   \n",
       "283  4.042353  280.126      -1.411709   -1.211143           1.753440   \n",
       "\n",
       "     Personal_consumption_expenditure  personal_savings  RSI (14D)  \\\n",
       "49                          -1.111277          0.346438  -0.393576   \n",
       "50                          -1.110459          0.472577  -0.191907   \n",
       "51                          -1.108638          0.693320   0.010196   \n",
       "52                          -1.101353          0.598716   0.109872   \n",
       "53                          -1.067593          0.882529   0.537577   \n",
       "..                                ...               ...        ...   \n",
       "279                          2.016264          1.071737   1.419937   \n",
       "280                          2.088586          0.314903   1.559019   \n",
       "281                          2.146814          0.125695   0.942353   \n",
       "282                          2.168300          0.157230   1.168795   \n",
       "283                          2.129077          0.504112   0.909048   \n",
       "\n",
       "     20 Day CCI  Williams %R      EMA (5D)      MA10      MA50  Target  \n",
       "49     0.125310     0.638341    463.315369 -0.809164 -0.823858       1  \n",
       "50     0.497262     0.775676    476.926911 -0.806501 -0.822199       1  \n",
       "51     0.829999     0.772793    494.121277 -0.804351 -0.820580       1  \n",
       "52     0.866166     0.736029    509.724182 -0.800951 -0.818937       1  \n",
       "53     1.474526     0.775468    540.512797 -0.792942 -0.816853       0  \n",
       "..          ...          ...           ...       ...       ...     ...  \n",
       "279    0.430587     0.773295  13577.078971  3.066925  1.513104       1  \n",
       "280    0.470339     0.748838  14154.512607  3.253312  1.579819       0  \n",
       "281    0.102715     0.433729  14291.908471  3.396147  1.641224       1  \n",
       "282    0.277095     0.777112  14726.578954  3.514513  1.709745       0  \n",
       "283    0.135297     0.475069  14902.402573  3.641662  1.778494       0  \n",
       "\n",
       "[235 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Initialize the Tkinter root window\n",
    "root = tk.Tk()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "root.withdraw()\n",
    "\n",
    "# Normalize data and assign movement direction values\n",
    "def prep(dataset):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    dataset['RSI (14D)'] = ta.rsi(dataset['Close'], length=14)\n",
    "    dataset['20 Day CCI'] = ta.cci(high=dataset['High'], low=dataset['Low'], \n",
    "                                   close=dataset['Close'], length=20)\n",
    "    dataset['Williams %R'] = ta.willr(high=dataset['High'], low=dataset['Low'], \n",
    "                                      close=dataset['Close'], length=14)\n",
    "    dataset['EMA (5D)'] = dataset['Close'].ewm(span=5, adjust=False).mean()\n",
    "\n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI (14D)', \n",
    "                '20 Day CCI', 'Williams %R', 'Mortgage_rate', 'Unemp_rate',\n",
    "                'disposable_income', 'Personal_consumption_expenditure', 'personal_savings']\n",
    "    \n",
    "    dataset[features] = dataset[features].astype(float)\n",
    "    dataset[features] = scaler.fit_transform(dataset[features])\n",
    "\n",
    "    dataset['MA10'] = dataset['Close'].rolling(window=10).mean()\n",
    "    dataset['MA50'] = dataset['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    dataset['Target'] = np.where(dataset['Close'].shift(-1) > dataset['Close'], 1, 0)\n",
    "    prepared_data = dataset.dropna().tail(503)\n",
    "\n",
    "    return prepared_data, scaler\n",
    "\n",
    "# Define LSTM Model class\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_layer = hidden_layer\n",
    "        #self.dropout_rate = dropout_rate\n",
    "        self.lstm = nn.LSTM(input_layer, hidden_layer, batch_first=True, bidirectional=False)\n",
    "        self.linear_layer = nn.Linear(hidden_layer, output_layer)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer).cuda(),\n",
    "                            torch.zeros(1,1,self.hidden_layer).cuda())\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        self.hidden_cell = (torch.zeros(1, input_tensor.size(0), self.hidden_layer).cuda(), \n",
    "                            torch.zeros(1, input_tensor.size(0), self.hidden_layer).cuda())\n",
    "        out, self.hidden_cell = self.lstm(input_tensor, self.hidden_cell)\n",
    "        lstm_out_last = out[:, -1, :]\n",
    "        predicted_values = self.linear_layer(lstm_out_last)\n",
    "        return predicted_values\n",
    "\n",
    "# Create sequences for input data and corresponding labels\n",
    "def create_sequence(input_data, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(input_data) - sequence_length):\n",
    "        sequence = input_data[i : i + sequence_length, :-1]\n",
    "        label = input_data[i + sequence_length, -1]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return sequences, labels\n",
    "\n",
    "# Convert sequences and labels to PyTorch tensors\n",
    "def convert_to_tensor(sequences, labels):\n",
    "    # Convert sequences and labels to tensors\n",
    "    sequences = [torch.tensor(seq, dtype=torch.float32) for seq in sequences]\n",
    "    labels = torch.tensor(labels, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    # Pad sequences\n",
    "    sequences = pad_sequence(sequences, batch_first=True)\n",
    "    \n",
    "    return sequences, labels\n",
    "\n",
    "# Train the model with data provided\n",
    "def trainer(model, train_data, val_data, loss_func, opt, epochs, device='cuda'):\n",
    "    train_errors, val_errors = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for sequence, labels in train_data:\n",
    "            opt.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer).to(device),\n",
    "                                 torch.zeros(1, 1, model.hidden_layer).to(device))\n",
    "            \n",
    "            sequence = sequence.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y = model(sequence)\n",
    "            loss = loss_func(y, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Compute average loss for the epoch\n",
    "        train_errors.append(epoch_loss / len(train_data))\n",
    "\n",
    "        # Validate the model\n",
    "        val_accuracy = evaluate_model(model, val_data, device)\n",
    "        val_errors.append(1 - val_accuracy)  # Convert accuracy to error\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % 25 == 1:\n",
    "            print(f'Epoch {epoch}, Training Loss: {epoch_loss / len(train_data)}, Validation Error: {1 - val_accuracy}')\n",
    "    \n",
    "    return train_errors, val_errors\n",
    "\n",
    "def evaluate_model(model, data_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    predictions, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for sequence, label in data_loader:\n",
    "            sequence = sequence.float().to(device)\n",
    "            output = model(sequence)\n",
    "            pred = torch.round(torch.sigmoid(output)).cpu().numpy()\n",
    "            predictions.extend(pred.flatten())\n",
    "            labels.extend(label.numpy())\n",
    "    return accuracy_score(labels, predictions)\n",
    "\n",
    "# Time Series Cross-Validation\n",
    "def time_series_cv(model_class, sequences, labels, n_splits, epochs, device='cuda'):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    accuracies = []\n",
    "\n",
    "    for train_index, test_index in tscv.split(sequences):\n",
    "        train_sequences, test_sequences = [sequences[i] for i in train_index], [sequences[i] for i in test_index]\n",
    "        train_labels, test_labels = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        train_sequences, train_labels = convert_to_tensor(train_sequences, train_labels)\n",
    "        test_sequences, test_labels = convert_to_tensor(test_sequences, test_labels)\n",
    "\n",
    "        # Create dataLoaders\n",
    "        train_data = torch.utils.data.DataLoader(list(zip(train_sequences, train_labels)), shuffle=True, batch_size=1)\n",
    "        test_data = torch.utils.data.DataLoader(list(zip(test_sequences, test_labels)), shuffle=False, batch_size=1)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = model_class(input_layer=10, hidden_layer=150, output_layer=1).to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Train and evaluate\n",
    "        train_errors, val_errors = trainer(model, train_data, test_data, loss_func, opt, epochs, device)\n",
    "        test_accuracy = evaluate_model(model, test_data, device)\n",
    "        accuracies.append(test_accuracy)\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Load and prepare data\n",
    "file_path = filedialog.askopenfilename(parent=root, title=\"Select A File\")\n",
    "ticker = pd.read_csv(file_path)\n",
    "ticker, scaler = prep(ticker)\n",
    "\n",
    "ticker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
